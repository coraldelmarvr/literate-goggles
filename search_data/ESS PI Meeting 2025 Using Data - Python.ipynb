{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coraldelmarvr/literate-goggles/blob/main/search_data/ESS%20PI%20Meeting%202025%20Using%20Data%20-%20Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9ffe901",
      "metadata": {
        "id": "b9ffe901"
      },
      "source": [
        "# Welcome to ESS-DIVE's Using Data Tutorial with Jupyter Notebook\n",
        "This Jupyter Notebook is a workflow to help data users find and access ESS-DIVE datasets, particularly those that employ file-level metadata and csv reporting formats. The workflow includes: <br>\n",
        "**[Part 1: Searching for Data](#-Part-1-Searching-on-ESS-DIVE)**\n",
        "\n",
        "    Use the ESS-DIVE Dataset API to search for dataset files\n",
        "**[Part 2: Exploring Inside Datasets](#-Part-2-Exploring-Inside-Datasets)**\n",
        "    \n",
        "    Basic searching inside datasets - look at individual files\n",
        "    Use API tools and dataset details to explore within a dataset - using File-level Metadata (flmd) and Data Dictionaires (DD)\n",
        "    Import data from csv files into python pandas dataframes\n",
        "**[Part 3: Starting Analysis](#-Part-3-Starting-Analysis)**\n",
        "    \n",
        "    Create simple visualizations with the data\n",
        "**[Part 4: Download Files and Log](#-Part-4-Download-Files-and-Save-the-Download-Log)**\n",
        "\n",
        "    Download files to local storage and log access details\n",
        "**[Part 5: Workflow Using Deep Dive API](#-Part-5-Workflow-Using-Deep-Dive-API)**\n",
        "\n",
        "    Try using the Fusion database and the Deep Dive API as an alternative for limited Search and deep Exploration\n",
        "**[EXTRA: Extra Resources](#-Part-5-Extra-Resources-and-Examples)**\n",
        "    \n",
        "    Explore Sample Metadata to explore datasets with sample-based data\n",
        "    And more!\n",
        "\n",
        "This was created as a resource to the PI Meeting 2025 ESS-DIVE Using Data Tutorial.\n",
        "\n",
        "Written By: Emily Nagamoto (she/her, LBNL), Danielle S Christianson (she/her, LBNL)\n",
        "\n",
        "Acknowledgements: This notebook builds from the 2024 ESS-DIVE Workshop [Using Data tutorial](https://github.com/ess-dive/essdive-tutorials/blob/main/search_data/Using_Data_with_Dataset_DeepDiveAPI_Python.ipynb) Danielle Christianson's [Finding and Accessing Data notebook](https://github.com/ess-dive/essdive-tutorials/blob/main/search_data/Tutorial_FindingAccessingData.ipynb), and Madison Burrus and Valerie Hendrix's Search & Download notebook.\n",
        "\n",
        "Last updated: 04/14/2025"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc060b07",
      "metadata": {
        "id": "bc060b07"
      },
      "source": [
        "## README: How to use this notebook\n",
        "You will be running the cells in sequential order. The notebook is designed that you can just run every cell without changing anything, or you can enter your own inputs into cells marked with <strong><span style=\"color:blue\">Enter INPUT</span></strong>. If a cell is not marked with <strong><span style=\"color:blue\">Enter INPUT</span></strong> or is marked with <strong><span style=\"color:green\">Run Cell</span></strong>, then just run the cell without making changes.\n",
        "\n",
        "Optional view cells are marked with \"Optional\" in the first line. These do not need to be run, but are included for additional visualization or guidance.\n",
        "\n",
        "Any downloaded files are logged with the date/time of access. See Section 4 to save the log.\n",
        "\n",
        "Workflows:\n",
        "* Cells in **Part 1-4** are sequential and depend on variables entered in prior cells.\n",
        "* To use **Part 5**: *Section A* replicates **Part 1** and *Section B* replicates **Part 2-3** using Deep Dive. To save the data, you can modify **Part 4**.\n",
        "* **EXTRA** requires a different notebook - [Finding and Accessing Data notebook](https://github.com/ess-dive/essdive-tutorials/blob/main/search_data/Tutorial_FindingAccessingData.ipynb).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1686044",
      "metadata": {
        "id": "c1686044"
      },
      "source": [
        "# SET-UP - Run before any other cells."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "485099d5-ffcb-46e3-98ff-183fe76c0791",
      "metadata": {
        "id": "485099d5-ffcb-46e3-98ff-183fe76c0791"
      },
      "source": [
        "### 1. Load packages that will be used later."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62853ae7-a22a-4a73-bd29-5a28bc7d4a50",
      "metadata": {
        "id": "62853ae7-a22a-4a73-bd29-5a28bc7d4a50"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7213b9c",
      "metadata": {
        "scrolled": true,
        "id": "c7213b9c"
      },
      "outputs": [],
      "source": [
        "# This notebook requires Python 3.\n",
        "import csv\n",
        "import datetime as dt\n",
        "import io\n",
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "import requests\n",
        "import urllib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from pathlib import Path\n",
        "from urllib.request import Request, urlopen, urlretrieve\n",
        "from zipfile import ZipFile\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccc94dd4-71cf-48f2-903a-f68eb6dae678",
      "metadata": {
        "id": "ccc94dd4-71cf-48f2-903a-f68eb6dae678"
      },
      "source": [
        "### 2. Configure authentification"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87eaa558-bc0b-436e-8dad-16b4e2332177",
      "metadata": {
        "id": "87eaa558-bc0b-436e-8dad-16b4e2332177"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong> <br>\n",
        "1. Go to ESS-DIVE (https://data.ess-dive.lbl.gov/data), login with your ORCID, and copy your authentication token from your account settings page.\n",
        "2. Run the following code cell.\n",
        "3. Paste your authentication token into the prompt as requested. Hit `Enter` key.\n",
        "\n",
        "   _Always re-run this code cell when you update your token. Tokens expire every 24 hours._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8a55298e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a55298e",
        "outputId": "d0bd6866-3ffa-4fc0-866b-a7142b1294a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token: eyJhbGciOiJSUzI1NiJ9.eyJzdWIiOiJodHRwOlwvXC9vcmNpZC5vcmdcLzAwMDktMDAwMy04NDQwLTU4M1giLCJmdWxsTmFtZSI6IkNvcmFsIGRlbCBNYXIgIFZhbGxlIFJvZHLDrWd1ZXoiLCJpc3N1ZWRBdCI6IjIwMjUtMDQtMTVUMTU6MzI6MzIuODQ4KzAwOjAwIiwiY29uc3VtZXJLZXkiOiJ0aGVjb25zdW1lcmtleSIsImV4cCI6MTc0NDc5NTk1MiwidXNlcklkIjoiaHR0cDpcL1wvb3JjaWQub3JnXC8wMDA5LTAwMDMtODQ0MC01ODNYIiwidHRsIjo2NDgwMCwiaWF0IjoxNzQ0NzMxMTUyfQ.j84aeSWRzq5j9IbR8lBc2bwGaqM31mYmy3WcgX9MITuIj16P3QoUonK_IMq6W1xUz_ci6KMVnDi3QbX3o5lHjZRgZpVhB4tItJHO4wwJeYPODyh1l2w2lvwQn6R6RoTue_KXhsi3Q-vnSOsNoap039Xm4gAozbi7h2SKNgtrjscURdbiwhep_Yxgz-_ocr18sQTxTf2RQtDTFUAIXlItA4zY5Oz08xLc-9saB1e7mD3TXcOfrWxcHcj_6enoDTJqNvPbr91zL9JdiJFhI-HhA_M9OAR0Yk00wnbJoWeUrJ_GGKFs3yhvmbqVIIfw5RQNP6aGffqRBZvx83gRe8ETug\n",
            "Success! Token is loaded.\n"
          ]
        }
      ],
      "source": [
        "token = input('Token: ')\n",
        "\n",
        "essdive_api_url = 'https://api.ess-dive.lbl.gov'\n",
        "\n",
        "essdive_direct_url = 'https://data.ess-dive.lbl.gov/catalog/d1/mn/v2/object/'\n",
        "\n",
        "essdive_deepdive_url = 'https://fusion.ess-dive.lbl.gov'\n",
        "\n",
        "print('Success! Token is loaded.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9950916",
      "metadata": {
        "id": "a9950916"
      },
      "source": [
        "### 3. Configure local storage for downloads\n",
        "\n",
        "This cell will grab the current directory path as the path to save any downloads. The code is configured to create a new folder in the current directory to save any files there."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "377582e4-2012-46e9-b5f9-cd035fc21fe6",
      "metadata": {
        "id": "377582e4-2012-46e9-b5f9-cd035fc21fe6"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "72008418",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72008418",
        "outputId": "7b717c7f-8db1-4197-b9c0-a72632448cdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory 'ESS-DIVE_Tutorial_Downloads' created\n",
            "Success! Local directory /content/ESS-DIVE_Tutorial_Downloads configured for downloads\n",
            "===================================\n",
            "Local directory is currently empty.\n",
            "===================================\n",
            "Downloaded files will be logged in the dictionary object \"download_file_log\".\n",
            "You can save this dictionary as a file later in the notebook.\n",
            "The filename, file url, and datetime accessed are recorded as a tuple in the \"downloaded_files\" element.\n"
          ]
        }
      ],
      "source": [
        "# make new folder in current local directory\n",
        "new_dir = 'ESS-DIVE_Tutorial_Downloads'\n",
        "parent_dir = os.getcwd()\n",
        "download_dir_path = Path(os.path.join(parent_dir, new_dir))\n",
        "try:\n",
        "    os.mkdir(download_dir_path)\n",
        "    print(\"Directory '% s' created\" % new_dir)\n",
        "except:\n",
        "    print(\"This directory already exists.\")\n",
        "\n",
        "if download_dir_path.exists():\n",
        "    print(f'Success! Local directory {download_dir_path} configured for downloads')\n",
        "    print('===================================')\n",
        "    current_files = [x for x in os.listdir(download_dir_path) if x != '.DS_Store']\n",
        "    if current_files:\n",
        "        print('Local directory contains: '+str(len(current_files)))\n",
        "    else:\n",
        "        print(f'Local directory is currently empty.')\n",
        "else:\n",
        "    print(f'Cannot find local directory {download_dir_path}. Please try again.')\n",
        "\n",
        "# create the file download log\n",
        "download_file_log = {}\n",
        "print('===================================')\n",
        "print('Downloaded files will be logged in the dictionary object \"download_file_log\".\\n'\n",
        "      'You can save this dictionary as a file later in the notebook.\\n'\n",
        "      'The filename, file url, and datetime accessed are recorded as a tuple in the \"downloaded_files\" element.')\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33756161",
      "metadata": {
        "id": "33756161"
      },
      "source": [
        "### 4. Load general functions\n",
        "\n",
        "These are helper functions that we made to make printing information, creating pandas dataframes, and calling the API easier. Feel free to copy these functions to other notebooks as needed. Once you run the following cell, the functions can be used at any point in the workflow"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9bfc228-e32b-4815-8f29-c6bca79d1cf1",
      "metadata": {
        "id": "a9bfc228-e32b-4815-8f29-c6bca79d1cf1"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "bc486f53",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc486f53",
        "outputId": "15503c22-137a-447d-82e2-86aba43aac44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Functions loaded.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def get_request(filename, f_url, stream=True):\n",
        "    \"\"\"\n",
        "    Get request for file, and stream the content back\n",
        "    \"\"\"\n",
        "\n",
        "    headers = {'user_agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:77.0) Gecko/20100101 Firefox/77.0',\n",
        "               'content-type': 'application/json'}\n",
        "    try:\n",
        "        r = requests.get(f_url, headers=headers, verify=True, stream=stream)\n",
        "        status_code = r.status_code\n",
        "        if status_code == 200:\n",
        "            return r\n",
        "        else:\n",
        "            print(f\"{filename} request returned {status_code}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"{filename} request unsuccessful: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def make_store(file_request, use_idx=True, print_headers=True):\n",
        "    \"\"\"\n",
        "    Read response and make store\n",
        "    \"\"\"\n",
        "    file_store = {}\n",
        "    csv_reader = csv.DictReader(file_request.iter_lines(decode_unicode=True))\n",
        "\n",
        "    for idx, row in enumerate(csv_reader):\n",
        "        if use_idx:\n",
        "            file_store.update({f'Index {idx}': row})\n",
        "            continue\n",
        "        fn = row.get('File_Name')\n",
        "        file_store.update({fn: row})\n",
        "\n",
        "    headers = list(row.keys())\n",
        "    if print_headers:\n",
        "        print(f\"File headers: {headers}\")\n",
        "    return headers, file_store\n",
        "\n",
        "\n",
        "def inspect_dataset_distribution(dataset_detail, file_type='all'):\n",
        "\n",
        "    print(dataset_detail.get('name'))\n",
        "    print('========================================')\n",
        "\n",
        "    count = 0\n",
        "    dist = dataset_detail.get('distribution')\n",
        "\n",
        "    for idx, file_info in enumerate(dist):\n",
        "        fn = file_info.get('name')\n",
        "        fn_url = file_info.get('contentUrl')\n",
        "        f_encoding = file_info.get('encodingFormat')\n",
        "        if file_type != 'all' and file_type not in f_encoding:\n",
        "            continue\n",
        "        print(f'Index {idx}: {fn}\\n  encoding: {f_encoding}\\n  url: {fn_url}')\n",
        "        count += 1\n",
        "\n",
        "    if count == 0:\n",
        "        print(f'No files found that match the file_type: \"{file_type}\" criteria.')\n",
        "\n",
        "\n",
        "def retrieve_file_from_essdive(file_url, file_path):\n",
        "    \"\"\" Retrieve the data file\n",
        "        file_path includes file name.\n",
        "    \"\"\"\n",
        "    error_messages = []\n",
        "    try:\n",
        "        urlretrieve(file_url, file_path)\n",
        "        return True, None\n",
        "    except Exception as e:\n",
        "        error_messages.append(f'Attempt 1 (no auth) failed: {e}')\n",
        "    try:\n",
        "        req = Request(file_url)\n",
        "        req.add_header('User-Agent', 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:77.0) Gecko/20100101 Firefox/77.0')\n",
        "        with urllib.request.urlopen(req) as response:\n",
        "            with open(file_path, 'wb') as out_file:\n",
        "                out_file.write(response.read())\n",
        "        return True, None\n",
        "    except Exception as e:\n",
        "        error_messages.append(f'Attempt 2 (no auth) failed: {e}')\n",
        "    try:\n",
        "        headers={\"Authorization\": f\"Bearer {token}\"}\n",
        "        request = urllib.request.Request(file_url, headers=headers)\n",
        "\n",
        "        with urllib.request.urlopen(request) as response:\n",
        "            with open(file_path, 'wb') as out_file:\n",
        "                out_file.write(response.read())\n",
        "        return True, None\n",
        "    except urllib.error.HTTPError as e:\n",
        "        error_messages.append(f'Attempt 3 (with token) failed: HTTP Error {e.code}: {e.reason}')\n",
        "    except Exception as e:\n",
        "        error_messages.append(f'Attempt 4 (with token) failed: {str(e)}')\n",
        "        return False, ' | '.join(error_messages)\n",
        "\n",
        "\n",
        "def download_selected_files(dataset_detail, file_indices, file_dir=download_dir_path, log_store=download_file_log, citation=None,\n",
        "                            is_csv_zipped=False, zip_download=None, zip_member_fn=None):\n",
        "    dist = dataset_detail.get('distribution')\n",
        "    ds_id = dataset_detail.get('@id')\n",
        "    #citation = dataset_detail.get('citation') << grabs related references but not the citation of the downloaded file\n",
        "    citation = citation\n",
        "    ds_name = dataset_detail.get('name')\n",
        "\n",
        "    if log_store is None:\n",
        "        log_store = {}\n",
        "\n",
        "    log_store.setdefault(ds_id, {'@id': ds_id, 'name': ds_name, 'citation': citation, 'downloaded_files': []})\n",
        "    ds_file_log = log_store.get(ds_id).get('downloaded_files')\n",
        "\n",
        "    print(f'Saving files in {download_dir_path}')\n",
        "    print(\"-------------------------------------\")\n",
        "\n",
        "    for idx, file_info in enumerate(dist):\n",
        "        msg = None\n",
        "        is_downloaded = None\n",
        "\n",
        "        if idx not in file_indices:\n",
        "            continue\n",
        "\n",
        "        fn = file_info.get('name')\n",
        "        file_path = download_dir_path / fn\n",
        "        fn_url = file_info.get('contentUrl')\n",
        "\n",
        "        if not is_csv_zipped:\n",
        "\n",
        "            download_ts = dt.datetime.now().isoformat()\n",
        "            is_downloaded, msg = retrieve_file_from_essdive(fn_url, file_path)\n",
        "\n",
        "        else:\n",
        "            if not zip_download or not zip_member_fn:\n",
        "                print('ZipFile object and zipped member file name are required. Try again.')\n",
        "                return None\n",
        "            try:\n",
        "                zip_download.extract(zip_member_fn, path=file_path)\n",
        "                if Path.exists(file_path / zip_member_fn):\n",
        "                    is_downloaded = True\n",
        "                    download_ts = dt.datetime.now().isoformat()\n",
        "                else:\n",
        "                    msg = f'Extraction of {zip_member_fn} from {fn} was not successful.'\n",
        "            except Exception as e:\n",
        "                msg = f'ERROR attempting to extract {zip_member_fn} from {fn}: {e}'\n",
        "\n",
        "        if is_downloaded:\n",
        "            print(f'--- {fn} downloaded')\n",
        "            ds_file_log.append((fn, fn_url, download_ts))\n",
        "        else:\n",
        "            print(msg)\n",
        "\n",
        "    print(\"-------------------------------------\")\n",
        "    print(f'Remember to cite these files! Dataset DOI {ds_id}, \\nDataset citation: {citation}')\n",
        "    return ds_id\n",
        "\n",
        "\n",
        "def inspect_zip_file_contents(dataset_detail, file_idx):\n",
        "    dist = dataset_detail.get('distribution')\n",
        "    file_info = dist[file_idx]\n",
        "\n",
        "    if not file_info:\n",
        "        print('File index not found. Please try again.')\n",
        "        return\n",
        "\n",
        "    fn = file_info.get('name')\n",
        "    if 'zip' not in file_info.get('encodingFormat'):\n",
        "        print(f'{fn} is not encoded as a zip file. Please select a different file.')\n",
        "\n",
        "    fn_url = file_info.get('contentUrl')\n",
        "\n",
        "    try:\n",
        "    # Create a request with headers\n",
        "        req = Request(fn_url)\n",
        "        req.add_header('User-Agent', 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:77.0) Gecko/20100101 Firefox/77.0')\n",
        "    # Open the URL with the added headers\n",
        "        resp = urlopen(req)\n",
        "        zip_download = ZipFile(io.BytesIO(resp.read()))\n",
        "        print('Success!')\n",
        "    except urllib.error.HTTPError as e:\n",
        "        print(f'HTTPError: {e.code} - {e.reason}')\n",
        "\n",
        "    # resp = urlopen(fn_url)\n",
        "\n",
        "    # zip_download = ZipFile(io.BytesIO(resp.read()))\n",
        "\n",
        "    print(f'{fn} contents:')\n",
        "    print('=================================')\n",
        "    for idx, file_member in enumerate(zip_download.namelist()):\n",
        "        print(f'Index {idx}: {file_member}')\n",
        "\n",
        "    return fn, zip_download\n",
        "\n",
        "\n",
        "def read_zipped_csv(zip_file_obj, csv_file_name, header_rows=1):\n",
        "    # with open(zip_file_obj, mode='r') as z:\n",
        "    #     csv_df = pd.read_csv(io.BytesIO(z.read(csv_file_name)))\n",
        "    csv_df = pd.read_csv(zip_download.open(csv_file_name), skiprows=header_rows)\n",
        "    return csv_df\n",
        "\n",
        "\n",
        "def grab_metadata(r_json): # for fusiondb\n",
        "    df = pd.DataFrame()\n",
        "    records = []\n",
        "\n",
        "    for dataset in r_json:\n",
        "        field_name = dataset['field_name']\n",
        "        unit = dataset['unit']\n",
        "        definition = dataset['definition']\n",
        "        data_type = dataset['data_type']\n",
        "        total_record_count = dataset['total_record_count']\n",
        "        values_summary = dataset['values_summary']\n",
        "        unit = dataset['unit']\n",
        "        doi = dataset['doi']\n",
        "        url = dataset['data_file_url']\n",
        "        data_file = dataset['data_file']\n",
        "        report={'Field_name':field_name, 'Unit':unit, 'Definition':definition, 'Data_type':data_type,\n",
        "                'Total_records':total_record_count,'Values':values_summary,'DOI':doi,\n",
        "                'URL':url,'File':data_file }\n",
        "        records.append(report)\n",
        "\n",
        "    df = pd.DataFrame(records)\n",
        "    return df\n",
        "\n",
        "# Change dataframe display options to better visualize the results\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.colheader_justify', 'left')\n",
        "\n",
        "print('Functions loaded.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73ca0947-3764-4a1a-9d1c-fa795702a9c3",
      "metadata": {
        "id": "73ca0947-3764-4a1a-9d1c-fa795702a9c3"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff350720",
      "metadata": {
        "id": "ff350720"
      },
      "source": [
        "# Part 1: Searching on ESS-DIVE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd24a2b0-e525-41cf-8043-9b195e2c9801",
      "metadata": {
        "id": "fd24a2b0-e525-41cf-8043-9b195e2c9801"
      },
      "source": [
        "## (A) Use the Dataset API tool\n",
        "Run this section to find datasets with the Dataset API tool. This section results in a list of potential datasets, and classification if it contains structured data or not."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbc721ea",
      "metadata": {
        "id": "cbc721ea"
      },
      "source": [
        "Use the ESS-DIVE Dataset API to search for datasets of interest.\n",
        "\n",
        "You can search for datasets using any of the following parameters:\n",
        "- Dataset Creator (**creator**): The creator/submitter of datasets\n",
        "- Date Published (**datePublished**): This is the date range of the publication of a package.\n",
        "- Project Name (**providerName**): The dataset project/provider that is set in the metadata.\n",
        "- Any text (**text**): Searches any metadata field that contains the passed text\n",
        "- Keywords (**keywords**): Search for datasets that have an exact match for all the given keywords.\n",
        "- Public datasets only (**isPublic**): If set with true, would only return public packages.\n",
        "\n",
        "**See additional details for dataset search in the ESS-DIVE package API techincal documentation:** https://api.ess-dive.lbl.gov/#/Data%20Package/listPackages.\n",
        "\n",
        "Use the [ESS-DIVE's project list](https://docs.google.com/spreadsheets/d/179SOyv42wXbP4owWZtUg3RqhW9dPOyENYcVYuUCcqwg/edit?usp=sharing) to find the options for project names."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eec89e6e-7697-473c-8fcb-fe8087b1e5be",
      "metadata": {
        "id": "eec89e6e-7697-473c-8fcb-fe8087b1e5be"
      },
      "source": [
        "### 1. Enter Search Parameters and make API call\n",
        "<strong><span style=\"color:blue\">Enter INPUT</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "257c91b7-1435-46ee-8cbd-c37efddc99eb",
      "metadata": {
        "id": "257c91b7-1435-46ee-8cbd-c37efddc99eb"
      },
      "outputs": [],
      "source": [
        "# Enter search terms: \"\\\"Leaf\"\\\" is an exact match, \"Leaf\" is any match\n",
        "#creater is the las name of the author or submitter\n",
        "creator=\"Serbin\"\n",
        "text= \"G-LiHT\"\n",
        "datePublished = \"[2019 TO 2021]\"  # \"<[YYYY TO YYYY-MM-DD]>\" # Not the same as data coverage"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "053d2289-359d-4487-acae-0838553b3dd2",
      "metadata": {
        "id": "053d2289-359d-4487-acae-0838553b3dd2"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c757ac3b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c757ac3b",
        "outputId": "abad077d-e745-475d-b1ae-6a6fe357e8ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success! Continue to look at the search results\n"
          ]
        }
      ],
      "source": [
        "# Contruct URL query to send to the ESS-DIVE packages API\n",
        "get_packages_response = f\"{essdive_api_url}/packages?creator={creator}&text={text}&datePublished={datePublished}&isPublic=true\"\n",
        "\n",
        "# Send request to API\n",
        "response = requests.get(get_packages_response, headers={\"Authorization\": f\"Bearer {token}\"})\n",
        "\n",
        "# Review the response and debug if needed\n",
        "if response.status_code == 200:\n",
        "    # Success\n",
        "    response_json = response.json()\n",
        "    print(\"Success! Continue to look at the search results\")\n",
        "else:\n",
        "    # There was an error\n",
        "    print(\"There was an error. Stop here and debug the issue. Email ess-dive-support@lbl.gov if you need assistance. \\n\")\n",
        "    print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15b678f5",
      "metadata": {
        "id": "15b678f5"
      },
      "source": [
        "### 2. Inspect the search results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5358753-40ec-4ec5-91a5-e5d10a6ab890",
      "metadata": {
        "id": "e5358753-40ec-4ec5-91a5-e5d10a6ab890"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "29c1ffee",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29c1ffee",
        "outputId": "8fd8fb2b-59b3-4c2d-b895-1e37e62f8c40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets found: 17\n",
            "-------------------\n",
            "Index: 0\n",
            "Evaluation of the One-point Method for Estimating Carboxylation Capacity, Utqiagvik (Barrow), Alaska and Upton, New York, 2018\n",
            "https://api.ess-dive.lbl.gov/packages/ess-dive-92b6d7de4f6722c-20250320T171720679\n",
            "https://data.ess-dive.lbl.gov/view/doi:10.5440/1506965\n",
            "Burnett A; Ely K; Davidson K; Serbin S; Rogers A (2019): Evaluation of the One-point Method for Estimating Carboxylation Capacity, Utqiagvik (Barrow), Alaska and Upton, New York, 2018. Next-Generation Ecosystem Experiments (NGEE) Arctic. Dataset. doi:10.5440/1506965\n",
            "-------------------\n",
            "Index: 1\n",
            "A Multi-Sensor Unoccupied Aerial System Improves Characterization of Vegetation Composition and Canopy Properties in the Arctic Tundra: Supporting Data\n",
            "https://api.ess-dive.lbl.gov/packages/ess-dive-3a53e1b91b26596-20250318T221944548\n",
            "https://data.ess-dive.lbl.gov/view/doi:10.5440/1647365\n",
            "Serbin S; Yang D; McMahon A (2020): A Multi-Sensor Unoccupied Aerial System Improves Characterization of Vegetation Composition and Canopy Properties in the Arctic Tundra: Supporting Data. Next-Generation Ecosystem Experiments (NGEE) Arctic. Dataset. doi:10.5440/1647365\n",
            "-------------------\n",
            "Index: 2\n",
            "G-LiHT Campaign Leaf Spectral Reflectance and Transmittance, Mar2017: Puerto Rico\n",
            "https://api.ess-dive.lbl.gov/packages/ess-dive-1bae01de65530b5-20241028T152402201539\n",
            "https://data.ess-dive.lbl.gov/view/doi:10.15486/NGT/1495204\n",
            "Serbin S; Meng R; Wu J; Ely K (2019): G-LiHT Campaign Leaf Spectral Reflectance and Transmittance, Mar2017: Puerto Rico. Next-Generation Ecosystem Experiments (NGEE) Tropics. Dataset. doi:10.15486/NGT/1495204\n",
            "-------------------\n",
            "Index: 3\n",
            "Leaf gas exchange and fitted parameters, San Lorenzo, Panama, 2020\n",
            "https://api.ess-dive.lbl.gov/packages/ess-dive-aef3af46c495e2d-20241028T152348276680\n",
            "https://data.ess-dive.lbl.gov/view/doi:10.15486/NGT/1781004\n",
            "Lamour J; Davidson K; Ely K; Anderson J; Serbin S; Rogers A (2021): Leaf gas exchange and fitted parameters, San Lorenzo, Panama, 2020. Next-Generation Ecosystem Experiments (NGEE) Tropics. Dataset. doi:10.15486/NGT/1781004\n",
            "-------------------\n",
            "Index: 4\n",
            "G-LiHT Campaign Leaf Carbon and Nitrogen Content, Mar2017: Puerto Rico\n",
            "https://api.ess-dive.lbl.gov/packages/ess-dive-e102679cbe8a2b5-20241028T152259077233\n",
            "https://data.ess-dive.lbl.gov/view/doi:10.15486/NGT/1905770\n",
            "Serbin S; Meng R; Wu J; Morrison B; Ely K (2021): G-LiHT Campaign Leaf Carbon and Nitrogen Content, Mar2017: Puerto Rico. Next-Generation Ecosystem Experiments (NGEE) Tropics. Dataset. doi:10.15486/NGT/1905770\n",
            "-------------------\n",
            "Index: 5\n",
            "Identification of key parameters controlling demographically structured vegetation dynamics in a Land Surface Model\n",
            "https://api.ess-dive.lbl.gov/packages/ess-dive-9a414f35143a820-20241028T152204817585\n",
            "https://data.ess-dive.lbl.gov/view/doi:10.15486/NGT/1497413\n",
            "Massoud E C; Xu C; Fisher R; Knox R; Walker A; Serbin S; Christoffersen B; Holm J; Kueppers L; Ricciuto D; Wei L; Johnson D; Chambers J; Koven C; McDowell N; Vrugt J A (2019): Identification of key parameters controlling demographically structured vegetation dynamics in a Land Surface Model. Next-Generation Ecosystem Experiments (NGEE) Tropics. Dataset. doi:10.15486/NGT/1497413\n",
            "-------------------\n",
            "Index: 6\n",
            "Diurnal leaf gas exchange survey, Feb2016-May2016, PA-SLZ, PA-PNM: Panama\n",
            "https://api.ess-dive.lbl.gov/packages/ess-dive-929b9848992f8ea-20241028T152049337817\n",
            "https://data.ess-dive.lbl.gov/view/doi:10.15486/NGT/1411972\n",
            "Rogers A; Serbin S; Ely K; Wu J; Wolfe B; Dickman T; Collins A; Detto M; Grossiord C; McDowell N; Michaletz S (2021): Diurnal leaf gas exchange survey, Feb2016-May2016, PA-SLZ, PA-PNM: Panama. Next-Generation Ecosystem Experiments (NGEE) Tropics. Dataset. doi:10.15486/NGT/1411972\n",
            "-------------------\n",
            "Index: 7\n",
            "CO2 response (ACi) gas exchange, calculated Vcmax & Jmax parameters, Feb2016-May2016, PA-SLZ, PA-PNM: Panama\n",
            "https://api.ess-dive.lbl.gov/packages/ess-dive-d2baf976424640d-20241028T151855675900\n",
            "https://data.ess-dive.lbl.gov/view/doi:10.15486/NGT/1411867\n",
            "Rogers A; Serbin S; Ely K; Wu J; Wolfe B; Dickman T; Collins A; Detto M; Grossiord C; McDowell N; Michaletz S (2021): CO2 response (ACi) gas exchange, calculated Vcmax & Jmax parameters, Feb2016-May2016, PA-SLZ, PA-PNM: Panama. Next-Generation Ecosystem Experiments (NGEE) Tropics. Dataset. doi:10.15486/NGT/1411867\n",
            "-------------------\n",
            "Index: 8\n",
            "G-LiHT Campaign Leaf Mass Area and Water Content, Mar2017: Puerto Rico\n",
            "https://api.ess-dive.lbl.gov/packages/ess-dive-ca2fc86b9122104-20241028T151754859073\n",
            "https://data.ess-dive.lbl.gov/view/doi:10.15486/NGT/1495202\n",
            "Serbin S; Meng R; Wu J; Ely K (2021): G-LiHT Campaign Leaf Mass Area and Water Content, Mar2017: Puerto Rico. Next-Generation Ecosystem Experiments (NGEE) Tropics. Dataset. doi:10.15486/NGT/1495202\n",
            "-------------------\n",
            "Index: 9\n",
            "G-LiHT Campaign Leaf Sample details & photos, March 2017: Puerto Rico\n",
            "https://api.ess-dive.lbl.gov/packages/ess-dive-bf58a2ab1d40f9f-20241028T151709835342\n",
            "https://data.ess-dive.lbl.gov/view/doi:10.15486/NGT/1781005\n",
            "Serbin S; Wu J; Meng R; Ely K (2021): G-LiHT Campaign Leaf Sample details & photos, March 2017: Puerto Rico. Next-Generation Ecosystem Experiments (NGEE) Tropics. Dataset. doi:10.15486/NGT/1781005\n",
            "-------------------\n",
            "Index: 10\n",
            "Vegetation Warming Experiment: 15N Uptake Experiment Arctagrostis latifolia Canopy Traits, Utqiagvik (Barrow), Alaska, 2018\n",
            "https://api.ess-dive.lbl.gov/packages/ess-dive-887439ab14e42ef-20240926T134607489\n",
            "https://data.ess-dive.lbl.gov/view/doi:10.5440/1784759\n",
            "Salmon V; Childs J; Iversen C; Spencer B; Rogers A; Ely K; Serbin S (2021): Vegetation Warming Experiment: 15N Uptake Experiment Arctagrostis latifolia Canopy Traits, Utqiagvik (Barrow), Alaska, 2018. Next-Generation Ecosystem Experiments (NGEE) Arctic. Dataset. doi:10.5440/1784759\n",
            "-------------------\n",
            "Index: 11\n",
            "Leaf Area Index (LAI) of vegetation at the Teller site, Seward Peninsula, Alaska, 2017\n",
            "https://api.ess-dive.lbl.gov/packages/ess-dive-fae0dbcdff768c7-20240702T162319031\n",
            "https://data.ess-dive.lbl.gov/view/doi:10.5440/1631418\n",
            "Serbin S (2020): Leaf Area Index (LAI) of vegetation at the Teller site, Seward Peninsula, Alaska, 2017. Next-Generation Ecosystem Experiments (NGEE) Arctic. Dataset. doi:10.5440/1631418\n",
            "-------------------\n",
            "Index: 12\n",
            "Leaf Photosynthetic Parameters: Quantum Yield, Convexity, Respiration, Gross CO2 Assimilation Rate and Raw Gas Exchange Data, Utqiagvik (Barrow), Alaska, 2016\n",
            "https://api.ess-dive.lbl.gov/packages/ess-dive-3b343d5f66758aa-20230809T150653268\n",
            "https://data.ess-dive.lbl.gov/view/doi:10.5440/1482338\n",
            "Rogers A; Ely K; Serbin S (2019): Leaf Photosynthetic Parameters: Quantum Yield, Convexity, Respiration, Gross CO2 Assimilation Rate and Raw Gas Exchange Data, Utqiagvik (Barrow), Alaska, 2016. Next-Generation Ecosystem Experiments (NGEE) Arctic. Dataset. doi:10.5440/1482338\n",
            "-------------------\n",
            "Index: 13\n",
            "Landscape-scale Characterization of Arctic Tundra Vegetation Composition, Structure, and Function with a Multi-sensor Unoccupied Aerial System: Supporting Data.\n",
            "https://api.ess-dive.lbl.gov/packages/ess-dive-8fce7d96f84db85-20230607T210824521467\n",
            "https://data.ess-dive.lbl.gov/view/doi:10.5440/1778212\n",
            "Serbin S; Yang D; McMahon A (2021): Landscape-scale Characterization of Arctic Tundra Vegetation Composition, Structure, and Function with a Multi-sensor Unoccupied Aerial System: Supporting Data.. Next-Generation Ecosystem Experiments (NGEE) Arctic. Dataset. doi:10.5440/1778212\n",
            "-------------------\n",
            "Index: 14\n",
            "Vegetation Warming Experiment: 15N Uptake Experiment Water-Extractable Soil Nutrients, Utqiagvik (Barrow), Alaska, 2018\n",
            "https://api.ess-dive.lbl.gov/packages/ess-dive-c2fa589311e79d7-20230407T144013754846\n",
            "https://data.ess-dive.lbl.gov/view/doi:10.5440/1784755\n",
            "Salmon V; Childs J; Iversen C; Spencer B; Rogers A; Ely K; Serbin S (2021): Vegetation Warming Experiment: 15N Uptake Experiment Water-Extractable Soil Nutrients, Utqiagvik (Barrow), Alaska, 2018. Next-Generation Ecosystem Experiments (NGEE) Arctic. Dataset. doi:10.5440/1784755\n",
            "-------------------\n",
            "Index: 15\n",
            "Vegetation Warming Experiment: 15N Uptake Experiment Inorganic Nitrogen and Phosphorus on Resins, Utqiagvik (Barrow), Alaska, 2018\n",
            "https://api.ess-dive.lbl.gov/packages/ess-dive-2f30849b852d19a-20230407T144000185864\n",
            "https://data.ess-dive.lbl.gov/view/doi:10.5440/1784752\n",
            "Salmon V; Childs J; Iversen C; Spencer B; Rogers A; Ely K; Serbin S (2021): Vegetation Warming Experiment: 15N Uptake Experiment Inorganic Nitrogen and Phosphorus on Resins, Utqiagvik (Barrow), Alaska, 2018. Next-Generation Ecosystem Experiments (NGEE) Arctic. Dataset. doi:10.5440/1784752\n",
            "-------------------\n",
            "Index: 16\n",
            "Leaf Carbon and Nitrogen Content, Seward Peninsula, Alaska, 2014\n",
            "https://api.ess-dive.lbl.gov/packages/ess-dive-4351ffbcaeb70a2-20230406T143613018506\n",
            "https://data.ess-dive.lbl.gov/view/doi:10.5440/1575068\n",
            "Rogers A; Alldred M; Serbin S (2020): Leaf Carbon and Nitrogen Content, Seward Peninsula, Alaska, 2014. Next-Generation Ecosystem Experiments (NGEE) Arctic. Dataset. doi:10.5440/1575068\n"
          ]
        }
      ],
      "source": [
        "# Here is a formatted version of what the response returns\n",
        "search_record_total = response_json['total']\n",
        "print(f\"Datasets found: {search_record_total}\")\n",
        "\n",
        "if search_record_total > 100:\n",
        "    print(\"The search API cannot return more than 100 results at a time. See documentation for how to paginate.\")\n",
        "\n",
        "candidate_datasets = response_json['result']\n",
        "\n",
        "for idx, dataset in enumerate(candidate_datasets):\n",
        "    print('-------------------')\n",
        "    print(f'Index: {idx}')\n",
        "    print(dataset.get('dataset').get('name'))\n",
        "    print(dataset.get('url'))\n",
        "    print(dataset.get('viewUrl'))\n",
        "    print(dataset.get('citation'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f78c2c08-a8f6-4a98-a508-cefbfa1326f5",
      "metadata": {
        "id": "f78c2c08-a8f6-4a98-a508-cefbfa1326f5"
      },
      "source": [
        "#### ***Optional***: Want to see what the JSON response look like? Run the cell below.\n",
        "This cell will be available for most calls that we make."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "2fbc3eb6",
      "metadata": {
        "scrolled": true,
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2fbc3eb6",
        "outputId": "9a25b5ac-43e6-493e-be24-ad6a4d3f57e4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'total': 17,\n",
              " 'user': 'http://orcid.org/0009-0003-8440-583X',\n",
              " 'query': {'isPublic': True,\n",
              "  'creator': 'Serbin',\n",
              "  'providerName': None,\n",
              "  'text': 'G-LiHT',\n",
              "  'datePublished': '[2019 TO 2021]',\n",
              "  'keywords': None},\n",
              " 'pageSize': 25,\n",
              " 'rowStart': 1,\n",
              " 'result': [{'id': 'ess-dive-92b6d7de4f6722c-20250320T171720679',\n",
              "   'viewUrl': 'https://data.ess-dive.lbl.gov/view/doi:10.5440/1506965',\n",
              "   'url': 'https://api.ess-dive.lbl.gov/packages/ess-dive-92b6d7de4f6722c-20250320T171720679',\n",
              "   'next': None,\n",
              "   'previous': 'https://api.ess-dive.lbl.gov/packages/ess-dive-246e76462718539-20250319T191515216',\n",
              "   'dateUploaded': '2025-03-20T17:17:22.626Z',\n",
              "   'dateModified': '2025-03-21T23:05:28.191Z',\n",
              "   'isPublic': True,\n",
              "   'citation': 'Burnett A; Ely K; Davidson K; Serbin S; Rogers A (2019): Evaluation of the One-point Method for Estimating Carboxylation Capacity, Utqiagvik (Barrow), Alaska and Upton, New York, 2018. Next-Generation Ecosystem Experiments (NGEE) Arctic. Dataset. doi:10.5440/1506965',\n",
              "   'dataset': {'@context': 'http://schema.org/',\n",
              "    '@type': 'Dataset',\n",
              "    '@id': 'doi:10.5440/1506965',\n",
              "    'name': 'Evaluation of the One-point Method for Estimating Carboxylation Capacity, Utqiagvik (Barrow), Alaska and Upton, New York, 2018',\n",
              "    'description': \"The maximum carboxylation efficiency of Rubisco (Vc,max) fitted from CO2 response curves and estimated from light-saturated photosynthesis using the one-point method. Data were collected in Utqiagvik (Barrow), AK and New York in 2018 on 6 species - Arctagrostis latifolia, Helianthus annuus, Populus canadensis, Phaseolus vulgaris, Quercus coccinea, Raphanus sativus. These data were used to compare fitted with estimated values of Vc,max to test the efficacy of the one-point method. Arctic data were used alongside temperate data for an evaluation of one-point gas exchange methodology, supported in part by NGEE Arctic. This dataset is comprised of fitted parameter values and raw gas exchange data files and metadata files in csv format. File formats have been updated from the original publication on the NGEE-Arctic archive, but the data has not been modified. The Next-Generation Ecosystem Experiments: Arctic (NGEE Arctic), was a research effort to reduce uncertainty in Earth System Models by developing a predictive understanding of carbon-rich Arctic ecosystems and feedbacks to climate. NGEE Arctic was supported by the Department of Energy's Office of Biological and Environmental Research. The NGEE Arctic project had two field research sites: 1) located within the Arctic polygonal tundra coastal region on the Barrow Environmental Observatory (BEO) and the North Slope near Utqiagvik (Barrow), Alaska and 2) multiple areas on the discontinuous permafrost region of the Seward Peninsula north of Nome, Alaska. Through observations, experiments, and synthesis with existing datasets, NGEE Arctic provided an enhanced knowledge base for multi-scale modeling and contributed to improved process representation at global pan-Arctic scales within the Department of Energy's Earth system Model (the Energy Exascale Earth System Model, or E3SM), and specifically within the E3SM Land Model component (ELM).\",\n",
              "    'datePublished': '2019'}},\n",
              "  {'id': 'ess-dive-3a53e1b91b26596-20250318T221944548',\n",
              "   'viewUrl': 'https://data.ess-dive.lbl.gov/view/doi:10.5440/1647365',\n",
              "   'url': 'https://api.ess-dive.lbl.gov/packages/ess-dive-3a53e1b91b26596-20250318T221944548',\n",
              "   'next': None,\n",
              "   'previous': 'https://api.ess-dive.lbl.gov/packages/ess-dive-680b3102e383219-20250318T220807660',\n",
              "   'dateUploaded': '2025-03-18T22:19:47.155Z',\n",
              "   'dateModified': '2025-03-21T23:19:15.911Z',\n",
              "   'isPublic': True,\n",
              "   'citation': 'Serbin S; Yang D; McMahon A (2020): A Multi-Sensor Unoccupied Aerial System Improves Characterization of Vegetation Composition and Canopy Properties in the Arctic Tundra: Supporting Data. Next-Generation Ecosystem Experiments (NGEE) Arctic. Dataset. doi:10.5440/1647365',\n",
              "   'dataset': {'@context': 'http://schema.org/',\n",
              "    '@type': 'Dataset',\n",
              "    '@id': 'doi:10.5440/1647365',\n",
              "    'name': 'A Multi-Sensor Unoccupied Aerial System Improves Characterization of Vegetation Composition and Canopy Properties in the Arctic Tundra: Supporting Data',\n",
              "    'description': 'Remote sensing data collected from Brookhaven National Laboratory\\'s (BNL) heavy-lift unoccupied aerial system (UAS) octocopter platform - the Osprey - operated by the Terrestrial Ecosystem Science and Technology (TEST) group. Data was collected from a single flight over the Kougarok hillslope site on 26 July, 2018. The Osprey is a multi-sensor UAS platform that simultaneously measures very high spatial resolution optical red/green/blue (RGB) and thermal infrared (TIR) surface \"skin\" temperature imagery, as well as surface reflectance at 1nm intervals in the visible to near-infrared spectral range from ~350-1000 nm measured at regular intervals along each flight path. Derived image products include ortho-mosaiced RGB and TIR images, an RGB-based digital surface model (DSM) using the structure from motion (SfM) technique, digital terrain model (DTM), and a canopy height model. Ancillary aircraft data, flight mission parameters, and general flight conditions are also included. This dataset includes *.pdf, *.txt, *.tif, *.dat, and *.csv with most zipped in *.tar.gz files. The Next-Generation Ecosystem Experiments: Arctic (NGEE Arctic), was a research effort to reduce uncertainty in Earth System Models by developing a predictive understanding of carbon-rich Arctic ecosystems and feedbacks to climate. NGEE Arctic was supported by the Department of Energy\\'s Office of Biological and Environmental Research. The NGEE Arctic project had two field research sites: 1) located within the Arctic polygonal tundra coastal region on the Barrow Environmental Observatory (BEO) and the North Slope near Utqiagvik (Barrow), Alaska and 2) multiple areas on the discontinuous permafrost region of the Seward Peninsula north of Nome, Alaska. Through observations, experiments, and synthesis with existing datasets, NGEE Arctic provided an enhanced knowledge base for multi-scale modeling and contributed to improved process representation at global pan-Arctic scales within the Department of Energy\\'s Earth system Model (the Energy Exascale Earth System Model, or E3SM), and specifically within the E3SM Land Model component (ELM).',\n",
              "    'datePublished': '2020'}},\n",
              "  {'id': 'ess-dive-1bae01de65530b5-20241028T152402201539',\n",
              "   'viewUrl': 'https://data.ess-dive.lbl.gov/view/doi:10.15486/NGT/1495204',\n",
              "   'url': 'https://api.ess-dive.lbl.gov/packages/ess-dive-1bae01de65530b5-20241028T152402201539',\n",
              "   'next': None,\n",
              "   'previous': 'https://api.ess-dive.lbl.gov/packages/ess-dive-01f86401781285d-20240913T180547097836',\n",
              "   'dateUploaded': '2024-10-28T15:24:06.360Z',\n",
              "   'dateModified': '2024-10-28T22:22:46.697Z',\n",
              "   'isPublic': True,\n",
              "   'citation': 'Serbin S; Meng R; Wu J; Ely K (2019): G-LiHT Campaign Leaf Spectral Reflectance and Transmittance, Mar2017: Puerto Rico. Next-Generation Ecosystem Experiments (NGEE) Tropics. Dataset. doi:10.15486/NGT/1495204',\n",
              "   'dataset': {'@context': 'http://schema.org/',\n",
              "    '@type': 'Dataset',\n",
              "    '@id': 'doi:10.15486/NGT/1495204',\n",
              "    'name': 'G-LiHT Campaign Leaf Spectral Reflectance and Transmittance, Mar2017: Puerto Rico',\n",
              "    'description': 'Measurements of leaf full-spectrum (i.e. 350-2500 nm) reflectance and transmittance across 54 tropical tree species from five sites in Puerto Rico. Sites are located in the Cambalache State Forest, Carite State Forest, Sabana Field Station, Fundacion Luis Munoz Marin and at the International Institute of Tropical Forestry at the University of Puerto Rico. Data includes leaves collected from fully sunlit and shaded canopy strata as well as leaves for young, mature, old and senescent leaf ages. Data for each sample includes the relative age estimate, leaf canopy position, and sample number. This data was collected as part of the 2017 NGEE-Tropics / NASA G-LiHT airborne campaign. See related datasets for sample details including photographs, leaf traits including leaf mass per area (LMA), water content, and leaf carbon and nitrogen.  This dataset was originally published on the NGEE Tropics Archive and is being mirrored on ESS-DIVE for long-term archival  Acknowledgement: This research was supported as part of NGEE-Tropics, funded by the U.S. Department of Energy, Office of Science, Office of Biological and Environmental Research under contract no. DE-SC0012704',\n",
              "    'datePublished': '2019'}},\n",
              "  {'id': 'ess-dive-aef3af46c495e2d-20241028T152348276680',\n",
              "   'viewUrl': 'https://data.ess-dive.lbl.gov/view/doi:10.15486/NGT/1781004',\n",
              "   'url': 'https://api.ess-dive.lbl.gov/packages/ess-dive-aef3af46c495e2d-20241028T152348276680',\n",
              "   'next': None,\n",
              "   'previous': 'https://api.ess-dive.lbl.gov/packages/ess-dive-fbfbcc003c2762b-20240913T180522398297',\n",
              "   'dateUploaded': '2024-10-28T15:23:52.799Z',\n",
              "   'dateModified': '2024-10-28T22:22:38.836Z',\n",
              "   'isPublic': True,\n",
              "   'citation': 'Lamour J; Davidson K; Ely K; Anderson J; Serbin S; Rogers A (2021): Leaf gas exchange and fitted parameters, San Lorenzo, Panama, 2020. Next-Generation Ecosystem Experiments (NGEE) Tropics. Dataset. doi:10.15486/NGT/1781004',\n",
              "   'dataset': {'@context': 'http://schema.org/',\n",
              "    '@type': 'Dataset',\n",
              "    '@id': 'doi:10.15486/NGT/1781004',\n",
              "    'name': 'Leaf gas exchange and fitted parameters, San Lorenzo, Panama, 2020',\n",
              "    'description': 'This data package contains photosynthetic CO2 response curves (ACi curves), light response curves (AQ curves), dark adapted dark respiration, conductance curves, and survey measurements for leaves measured at the San Lorenzo forest canopy crane site, Panama (PA-SLZ) from January to March 2020. Leaves were sampled from both the top of the canopy and multiple heights within the canopy from 10 vertical profiles and included around 50 species. In addition, six core species were also measured, from the top of the canopy. Fitted maximum carboxylation rate (Vcmax), maximum electron transport rate (Jmax), and triose phosphate utilization rate (TPU) were derived from measured data as well as the convexity, light use efficiency, apparent quantum yield, and Rdark. The measurements can also be used to derive the conductance parameters g0 and g1 of stomatal model. All the gas exchange data and metadata are presented in .csv files and complete instrument output are included in .zip folders. Data and metadata meet the ESS-DIVE leaf-level gas exchange reporting format requirements. The protocol details are provided as pdf documents. In addition to gas exchange data described here these samples were also used for measurement of leaf optical properties, carbon and nitrogen content, and leaf mass per unit leaf area (LMA) these data can be cross linked using the unique sample ID and are provided in separate related data packages. Sample information including canopy elevation and leaf area index (LAI) can be found in the related Leaf and canopy traits data package.  This dataset was originally published on the NGEE Tropics Archive and is being mirrored on ESS-DIVE for long-term archival  Acknowledgement: This research was supported as part of NGEE-Tropics, funded by the U.S. Department of Energy, Office of Science, Office of Biological and Environmental Research under contract no. DE-SC0012704.',\n",
              "    'datePublished': '2021'}},\n",
              "  {'id': 'ess-dive-e102679cbe8a2b5-20241028T152259077233',\n",
              "   'viewUrl': 'https://data.ess-dive.lbl.gov/view/doi:10.15486/NGT/1905770',\n",
              "   'url': 'https://api.ess-dive.lbl.gov/packages/ess-dive-e102679cbe8a2b5-20241028T152259077233',\n",
              "   'next': None,\n",
              "   'previous': 'https://api.ess-dive.lbl.gov/packages/ess-dive-d45dc5c37c6591d-20240913T180459468684',\n",
              "   'dateUploaded': '2024-10-28T15:23:03.756Z',\n",
              "   'dateModified': '2024-10-28T22:58:24.743Z',\n",
              "   'isPublic': True,\n",
              "   'citation': 'Serbin S; Meng R; Wu J; Morrison B; Ely K (2021): G-LiHT Campaign Leaf Carbon and Nitrogen Content, Mar2017: Puerto Rico. Next-Generation Ecosystem Experiments (NGEE) Tropics. Dataset. doi:10.15486/NGT/1905770',\n",
              "   'dataset': {'@context': 'http://schema.org/',\n",
              "    '@type': 'Dataset',\n",
              "    '@id': 'doi:10.15486/NGT/1905770',\n",
              "    'name': 'G-LiHT Campaign Leaf Carbon and Nitrogen Content, Mar2017: Puerto Rico',\n",
              "    'description': 'Measurements of leaf carbon and nitrogen content collected from 68 tropical tree species. Data includes leaves collected from fully sunlit and shaded canopy strata as well as leaves for young, mature, old and senescent leaf ages. Data for each sample includes the relative age estimate, leaf canopy position and sample number. This data was collected as part of the 2017 NGEE-Tropics / NASA G-LiHT airborne campaign. This data package includes processed data for leaf carbon and nitrogen content (*.csv). Metadata files include data description (_dd.csv) for tabular data, site information (*.csv), sampling protocol (*.pdf) and the NGEE-Tropics FRAMES e-field log and file submission metadata (*.xlsx). See related datasets for sample details including photographs, leaf-level reflectance and transmittance spectra, leaf mass per area (LMA) and water content.  This dataset was originally published on the NGEE Tropics Archive and is being mirrored on ESS-DIVE for long-term archival  Acknowledgement: This research was supported as part of NGEE-Tropics, funded by the U.S. Department of Energy, Office of Science, Office of Biological and Environmental Research under contract no. DE-SC0012704.',\n",
              "    'datePublished': '2021'}},\n",
              "  {'id': 'ess-dive-9a414f35143a820-20241028T152204817585',\n",
              "   'viewUrl': 'https://data.ess-dive.lbl.gov/view/doi:10.15486/NGT/1497413',\n",
              "   'url': 'https://api.ess-dive.lbl.gov/packages/ess-dive-9a414f35143a820-20241028T152204817585',\n",
              "   'next': None,\n",
              "   'previous': 'https://api.ess-dive.lbl.gov/packages/ess-dive-6803b611d3eae80-20240913T180404580110',\n",
              "   'dateUploaded': '2024-10-28T15:22:10.961Z',\n",
              "   'dateModified': '2024-10-28T22:57:21.894Z',\n",
              "   'isPublic': True,\n",
              "   'citation': 'Massoud E C; Xu C; Fisher R; Knox R; Walker A; Serbin S; Christoffersen B; Holm J; Kueppers L; Ricciuto D; Wei L; Johnson D; Chambers J; Koven C; McDowell N; Vrugt J A (2019): Identification of key parameters controlling demographically structured vegetation dynamics in a Land Surface Model. Next-Generation Ecosystem Experiments (NGEE) Tropics. Dataset. doi:10.15486/NGT/1497413',\n",
              "   'dataset': {'@context': 'http://schema.org/',\n",
              "    '@type': 'Dataset',\n",
              "    '@id': 'doi:10.15486/NGT/1497413',\n",
              "    'name': 'Identification of key parameters controlling demographically structured vegetation dynamics in a Land Surface Model',\n",
              "    'description': 'This dataset includes outputs of 5000 simulations of CLM4.5(ED) to quantify the sensitivity of the model outputs to changes in model parameters using the Fourier Amplitude Sensitivity Test (FAST). Each simulation is generated by simultaneously sampling from 15% deviations of the default values of >80 vegetation parameters. This dataset includes 1) model codes of CLM4.5(ED) used for the sensitivity analysis; 2) the parameter samples;  and 3) the corresponding model outputs of vegetation status (e.g., Gross Primary Production, Leaf Area Index and Biomass) and demography (e.g., diameter growth and mortality rates).  The outputs are organized to the format of the FAST toolbox (https://sites.google.com/site/xuchongang/uasatoolbox).  This dataset was originally published on the NGEE Tropics Archive and is being mirrored on ESS-DIVE for long-term archival',\n",
              "    'datePublished': '2019'}},\n",
              "  {'id': 'ess-dive-929b9848992f8ea-20241028T152049337817',\n",
              "   'viewUrl': 'https://data.ess-dive.lbl.gov/view/doi:10.15486/NGT/1411972',\n",
              "   'url': 'https://api.ess-dive.lbl.gov/packages/ess-dive-929b9848992f8ea-20241028T152049337817',\n",
              "   'next': None,\n",
              "   'previous': 'https://api.ess-dive.lbl.gov/packages/ess-dive-956acc85c84901a-20240913T175835426688',\n",
              "   'dateUploaded': '2024-10-28T15:20:55.392Z',\n",
              "   'dateModified': '2024-10-28T22:56:24.751Z',\n",
              "   'isPublic': True,\n",
              "   'citation': 'Rogers A; Serbin S; Ely K; Wu J; Wolfe B; Dickman T; Collins A; Detto M; Grossiord C; McDowell N; Michaletz S (2021): Diurnal leaf gas exchange survey, Feb2016-May2016, PA-SLZ, PA-PNM: Panama. Next-Generation Ecosystem Experiments (NGEE) Tropics. Dataset. doi:10.15486/NGT/1411972',\n",
              "   'dataset': {'@context': 'http://schema.org/',\n",
              "    '@type': 'Dataset',\n",
              "    '@id': 'doi:10.15486/NGT/1411972',\n",
              "    'name': 'Diurnal leaf gas exchange survey, Feb2016-May2016, PA-SLZ, PA-PNM: Panama',\n",
              "    'description': 'This data package contains the results of a diurnal leaf gas exchange survey measured on sunlit canopy trees within the NGEE Tropics sites Parque Natural Metropolitano (PA-PNM) and Bosque Protector San Lorenzo (PA-SLZ) in Panama. Measurements were taken on a monthly basis from February to May of 2016. This data was collected as part of the 2016 El Nio-Southern Oscillation (ENSO) campaign. Included in this data package are two Excel files with data (2016ENSO_Panama_DiurnalGasEx, 2016ENSO_Panama_AreaCorrections) and additional Excel files with associated metadata. Microsoft Excel or other spreadsheet applications can be used to utilize these files. Also included is a PDF document (Metadata_description_2016_ENSO_Panama) with details such as data collection methods, equipment used, and site information. See related datasets for further sample details, leaf water potential, LMA, leaf spectra, other gas exchange and leaf chemistry. VERSION 2 update. The identification of a species from the PNM site has been corrected as follows: the identification of the tree initially identified as Pseudosamanea guachapele (ALBIED) has been revised to Albizia adinocephala (ALBIAD). The updated data package includes revised data, metadata and protocol documents updated to reflect this change.  This dataset was originally published on the NGEE Tropics Archive and is being mirrored on ESS-DIVE for long-term archival  Acknowledgement: This research was supported as part of NGEE-Tropics, funded by the U.S. Department of Energy, Office of Science, Office of Biological and Environmental Research under contract no. DE-SC0012704.',\n",
              "    'datePublished': '2021'}},\n",
              "  {'id': 'ess-dive-d2baf976424640d-20241028T151855675900',\n",
              "   'viewUrl': 'https://data.ess-dive.lbl.gov/view/doi:10.15486/NGT/1411867',\n",
              "   'url': 'https://api.ess-dive.lbl.gov/packages/ess-dive-d2baf976424640d-20241028T151855675900',\n",
              "   'next': None,\n",
              "   'previous': 'https://api.ess-dive.lbl.gov/packages/ess-dive-32df38aa2158e8d-20240913T175711302846',\n",
              "   'dateUploaded': '2024-10-28T15:19:02.939Z',\n",
              "   'dateModified': '2024-10-28T22:55:04.013Z',\n",
              "   'isPublic': True,\n",
              "   'citation': 'Rogers A; Serbin S; Ely K; Wu J; Wolfe B; Dickman T; Collins A; Detto M; Grossiord C; McDowell N; Michaletz S (2021): CO2 response (ACi) gas exchange, calculated Vcmax & Jmax parameters, Feb2016-May2016, PA-SLZ, PA-PNM: Panama. Next-Generation Ecosystem Experiments (NGEE) Tropics. Dataset. doi:10.15486/NGT/1411867',\n",
              "   'dataset': {'@context': 'http://schema.org/',\n",
              "    '@type': 'Dataset',\n",
              "    '@id': 'doi:10.15486/NGT/1411867',\n",
              "    'name': 'CO2 response (ACi) gas exchange, calculated Vcmax & Jmax parameters, Feb2016-May2016, PA-SLZ, PA-PNM: Panama',\n",
              "    'description': 'This data package contains CO2 response (ACi) gas exchange and fitted Vcmax and Jmax parameters measured on sunlit canopy trees within the NGEE Tropics sites Parque Natural Metropolitano (PA-PNM) and Bosque Protector San Lorenzo (PA-SLZ) in Panama. Measurements were taken on a monthly basis from February to May of 2016. This data was collected as part of the 2016 El Nio-Southern Oscillation (ENSO) campaign. Included in this data package are two Excel files with data (2016ENSO_Panama_ACi, 2016ENSO_Panama_Fitted_Vcmax_Jmax) and three Excel files with associated metadata. Also included is a Word document (Metadata_description_2016_ENSO_Panama) with details such as data collection methods, equipment used, and site information and a pdf (NGEE_Tropics_ENSO_Aci_Protocol_V2). See related datasets for further sample details, leaf water potential, LMA, leaf spectra, diurnal gas exchange and leaf chemistry.VERSION 2 update. The identification of a species from the PNM site has been corrected as follows: the identification of the tree initially identified as Pseudosamanea guachapele (ALBIED) has been revised to Albizia adinocephala (ALBIAD). The updated data package includes revised data, metadata and protocol documents updated to reflect this change.  This dataset was originally published on the NGEE Tropics Archive and is being mirrored on ESS-DIVE for long-term archival  Acknowledgement: This research was supported as part of NGEE-Tropics, funded by the U.S. Department of Energy, Office of Science, Office of Biological and Environmental Research under contract no. DE-SC0012704.',\n",
              "    'datePublished': '2021'}},\n",
              "  {'id': 'ess-dive-ca2fc86b9122104-20241028T151754859073',\n",
              "   'viewUrl': 'https://data.ess-dive.lbl.gov/view/doi:10.15486/NGT/1495202',\n",
              "   'url': 'https://api.ess-dive.lbl.gov/packages/ess-dive-ca2fc86b9122104-20241028T151754859073',\n",
              "   'next': None,\n",
              "   'previous': 'https://api.ess-dive.lbl.gov/packages/ess-dive-a1ead13fe8ca36e-20240913T175616259906',\n",
              "   'dateUploaded': '2024-10-28T15:17:59.721Z',\n",
              "   'dateModified': '2024-10-28T22:54:07.007Z',\n",
              "   'isPublic': True,\n",
              "   'citation': 'Serbin S; Meng R; Wu J; Ely K (2021): G-LiHT Campaign Leaf Mass Area and Water Content, Mar2017: Puerto Rico. Next-Generation Ecosystem Experiments (NGEE) Tropics. Dataset. doi:10.15486/NGT/1495202',\n",
              "   'dataset': {'@context': 'http://schema.org/',\n",
              "    '@type': 'Dataset',\n",
              "    '@id': 'doi:10.15486/NGT/1495202',\n",
              "    'name': 'G-LiHT Campaign Leaf Mass Area and Water Content, Mar2017: Puerto Rico',\n",
              "    'description': 'This data package contains measurements of leaf mass per area (LMA) and fresh-leaf water content collected from 54 tropical tree species across five sites in Puerto Rico. Data includes leaves collected from fully sunlit and shaded canopy strata as well as leaves for young, mature, old, and senescent leaf ages. Data for each sample includes the relative age estimate, leaf canopy position, and sample number. Included in the attached zip file are two Excel files with metadata (E-Field_Log_2017_BNL_PuertoRico.xlsx and File_Submission_Metadata_2017_PR_LMA.xlsx) and two data files (NGEE-Tropics_Puerto_Rico_March2017_LMA.xlsx and NGEE-Tropics_Puerto_Rico_March2017_Leaf_Sample_Detail.xlsx). This data was collected as part of the 2017 NGEE-Tropics / NASA G-LiHT airborne campaign. See related datasets for sample details including photographs, leaf-level optical properties (i.e. reflectance and transmittance) and leaf carbon and nitrogen.  This dataset was originally published on the NGEE Tropics Archive and is being mirrored on ESS-DIVE for long-term archival  Acknowledgement: This research was supported as part of NGEE-Tropics, funded by the U.S. Department of Energy, Office of Science, Office of Biological and Environmental Research under contract no. DE-SC0012704.',\n",
              "    'datePublished': '2021'}},\n",
              "  {'id': 'ess-dive-bf58a2ab1d40f9f-20241028T151709835342',\n",
              "   'viewUrl': 'https://data.ess-dive.lbl.gov/view/doi:10.15486/NGT/1781005',\n",
              "   'url': 'https://api.ess-dive.lbl.gov/packages/ess-dive-bf58a2ab1d40f9f-20241028T151709835342',\n",
              "   'next': None,\n",
              "   'previous': 'https://api.ess-dive.lbl.gov/packages/ess-dive-c51ab2e1453bc12-20240913T175524252589',\n",
              "   'dateUploaded': '2024-10-28T15:17:14.133Z',\n",
              "   'dateModified': '2024-10-28T22:53:14.520Z',\n",
              "   'isPublic': True,\n",
              "   'citation': 'Serbin S; Wu J; Meng R; Ely K (2021): G-LiHT Campaign Leaf Sample details & photos, March 2017: Puerto Rico. Next-Generation Ecosystem Experiments (NGEE) Tropics. Dataset. doi:10.15486/NGT/1781005',\n",
              "   'dataset': {'@context': 'http://schema.org/',\n",
              "    '@type': 'Dataset',\n",
              "    '@id': 'doi:10.15486/NGT/1781005',\n",
              "    'name': 'G-LiHT Campaign Leaf Sample details & photos, March 2017: Puerto Rico',\n",
              "    'description': 'This data package includes details of leaves sampled for leaf spectra and chemistry from 5 sites in Puerto Rico, in March of 2017. Sunlit canopy and shaded leaves of 66 species were collected. Data for each sample includes species, leaf age, type of analysis (spectroscopy, gas exchange, chemistry), sample number and sample photographs. The data package includes a spreadsheet with sample information and a zip file of photographs (1.6 GB). This data was collected as part of the 2017 BNLG-LiHT leaf spectra campaign. See related datasets for leaf spectral reflectance and transmittance, leaf mass area (LMA), and leaf chemistry. Note that leaf sample details are also included in related datasets.  This dataset was originally published on the NGEE Tropics Archive and is being mirrored on ESS-DIVE for long-term archival  Acknowledgement: This research was supported as part of NGEE-Tropics, funded by the U.S. Department of Energy, Office of Science, Office of Biological and Environmental Research under contract no. DE-SC0012704.',\n",
              "    'datePublished': '2021'}},\n",
              "  {'id': 'ess-dive-887439ab14e42ef-20240926T134607489',\n",
              "   'viewUrl': 'https://data.ess-dive.lbl.gov/view/doi:10.5440/1784759',\n",
              "   'url': 'https://api.ess-dive.lbl.gov/packages/ess-dive-887439ab14e42ef-20240926T134607489',\n",
              "   'next': None,\n",
              "   'previous': 'https://api.ess-dive.lbl.gov/packages/ess-dive-b05e82ee134402b-20230630T222357059490',\n",
              "   'dateUploaded': '2024-09-26T13:46:10.088Z',\n",
              "   'dateModified': '2024-10-15T00:02:39.201Z',\n",
              "   'isPublic': True,\n",
              "   'citation': 'Salmon V; Childs J; Iversen C; Spencer B; Rogers A; Ely K; Serbin S (2021): Vegetation Warming Experiment: 15N Uptake Experiment Arctagrostis latifolia Canopy Traits, Utqiagvik (Barrow), Alaska, 2018. Next-Generation Ecosystem Experiments (NGEE) Arctic. Dataset. doi:10.5440/1784759',\n",
              "   'dataset': {'@context': 'http://schema.org/',\n",
              "    '@type': 'Dataset',\n",
              "    '@id': 'doi:10.5440/1784759',\n",
              "    'name': 'Vegetation Warming Experiment: 15N Uptake Experiment Arctagrostis latifolia Canopy Traits, Utqiagvik (Barrow), Alaska, 2018',\n",
              "    'description': \"This dataset consists of measured Arctagrostis latifolia canopy traits harvested from vegetation warming experiment enclosures and paired control plots located on the BEO, Utqiavik, Alaska. Harvest types include both natural abundance and enriched A. latifolia. Canopy traits measured include leaf area index (LAI), specific leaf area (SLA) and maximum height. Vegetation warming chambers (Zero Power) were deployed on the Barrow Environmental Observatory (BEO), Utqiavik, Alaska. These chambers (Figure 1) consistently elevated air temperatures by approximately 4C using a self-venting system described by Lewin et al (2017). Five chambers were deployed from June 17, 2018 to September 24, 2018 on the BEO within a 1 km2 area centered on 71.275N, -156.641W. Each chamber was co-located with an ambient plot where temperatures were not manipulated on patches of tundra containing the target species Arctagrostis latifolia. An intensive field campaign in late July investigated the impact of warming had on A. latifolia biomass, chemistry, and uptake of 15N labeled ammonia that was injected into the surface soils for one week. Initial measurements were taken on July 21, 2018. Harvest occurred on July 27, 2018. Water-extractable nutrients in soils were measured in July following harvests of A. latifolia plants and underlying soils. Availability of ammonia, nitrate, and phosphate throughout the growing season was measured by extracting nutrients bound to anion and cation binding resins deployed from July through September. Environmental variables (thaw depth, surface soil temperatures, surface soil moisture) were measured. Leaf traits and root traits of A. latifolia were also measured. This dataset includes one csv file and one pdf file. The Next-Generation Ecosystem Experiments: Arctic (NGEE Arctic), was a research effort to reduce uncertainty in Earth System Models by developing a predictive understanding of carbon-rich Arctic ecosystems and feedbacks to climate. NGEE Arctic was supported by the Department of Energy's Office of Biological and Environmental Research. The NGEE Arctic project had two field research sites: 1) located within the Arctic polygonal tundra coastal region on the Barrow Environmental Observatory (BEO) and the North Slope near Utqiagvik (Barrow), Alaska and 2) multiple areas on the discontinuous permafrost region of the Seward Peninsula north of Nome, Alaska. Through observations, experiments, and synthesis with existing datasets, NGEE Arctic provided an enhanced knowledge base for multi-scale modeling and contributed to improved process representation at global pan-Arctic scales within the Department of Energy's Earth system Model (the Energy Exascale Earth System Model, or E3SM), and specifically within the E3SM Land Model component (ELM).\",\n",
              "    'datePublished': '2021'}},\n",
              "  {'id': 'ess-dive-fae0dbcdff768c7-20240702T162319031',\n",
              "   'viewUrl': 'https://data.ess-dive.lbl.gov/view/doi:10.5440/1631418',\n",
              "   'url': 'https://api.ess-dive.lbl.gov/packages/ess-dive-fae0dbcdff768c7-20240702T162319031',\n",
              "   'next': None,\n",
              "   'previous': 'https://api.ess-dive.lbl.gov/packages/ess-dive-f1130d0da8d608f-20240702T161640952509',\n",
              "   'dateUploaded': '2024-07-02T16:23:21.089Z',\n",
              "   'dateModified': '2024-07-24T19:02:12.914Z',\n",
              "   'isPublic': True,\n",
              "   'citation': 'Serbin S (2020): Leaf Area Index (LAI) of vegetation at the Teller site, Seward Peninsula, Alaska, 2017. Next-Generation Ecosystem Experiments (NGEE) Arctic. Dataset. doi:10.5440/1631418',\n",
              "   'dataset': {'@context': 'http://schema.org/',\n",
              "    '@type': 'Dataset',\n",
              "    '@id': 'doi:10.5440/1631418',\n",
              "    'name': 'Leaf Area Index (LAI) of vegetation at the Teller site, Seward Peninsula, Alaska, 2017',\n",
              "    'description': 'Measurements of leaf area index (LAI) at 299 locations on the \"tall shrub transect\" at the NGEE Arctic Teller field site. Measurements were made on 2017-07-27 using a LiCor LAI-2200. The dataset includes 9 files as dGPS locations, raw measurements, processed data and R script used for processing. The Next-Generation Ecosystem Experiments: Arctic (NGEE Arctic), was a research effort to reduce uncertainty in Earth System Models by developing a predictive understanding of carbon-rich Arctic ecosystems and feedbacks to climate. NGEE Arctic was supported by the Department of Energy\\'s Office of Biological and Environmental Research. The NGEE Arctic project had two field research sites: 1) located within the Arctic polygonal tundra coastal region on the Barrow Environmental Observatory (BEO) and the North Slope near Utqiagvik (Barrow), Alaska and 2) multiple areas on the discontinuous permafrost region of the Seward Peninsula north of Nome, Alaska. Through observations, experiments, and synthesis with existing datasets, NGEE Arctic provided an enhanced knowledge base for multi-scale modeling and contributed to improved process representation at global pan-Arctic scales within the Department of Energy\\'s Earth system Model (the Energy Exascale Earth System Model, or E3SM), and specifically within the E3SM Land Model component (ELM).',\n",
              "    'datePublished': '2020'}},\n",
              "  {'id': 'ess-dive-3b343d5f66758aa-20230809T150653268',\n",
              "   'viewUrl': 'https://data.ess-dive.lbl.gov/view/doi:10.5440/1482338',\n",
              "   'url': 'https://api.ess-dive.lbl.gov/packages/ess-dive-3b343d5f66758aa-20230809T150653268',\n",
              "   'next': None,\n",
              "   'previous': 'https://api.ess-dive.lbl.gov/packages/ess-dive-3b343d5f66758aa-20230809T150513302',\n",
              "   'dateUploaded': '2023-08-09T15:06:53.965Z',\n",
              "   'dateModified': '2024-07-24T18:58:42.869Z',\n",
              "   'isPublic': True,\n",
              "   'citation': 'Rogers A; Ely K; Serbin S (2019): Leaf Photosynthetic Parameters: Quantum Yield, Convexity, Respiration, Gross CO2 Assimilation Rate and Raw Gas Exchange Data, Utqiagvik (Barrow), Alaska, 2016. Next-Generation Ecosystem Experiments (NGEE) Arctic. Dataset. doi:10.5440/1482338',\n",
              "   'dataset': {'@context': 'http://schema.org/',\n",
              "    '@type': 'Dataset',\n",
              "    '@id': 'doi:10.5440/1482338',\n",
              "    'name': 'Leaf Photosynthetic Parameters: Quantum Yield, Convexity, Respiration, Gross CO2 Assimilation Rate and Raw Gas Exchange Data, Utqiagvik (Barrow), Alaska, 2016',\n",
              "    'description': 'Leaf photosynthetic parameters including quantum yield, convexity, respiration and gross CO2 assimilation rate determined from the response of photosynthesis to irradiance and supporting raw gas exchange data. Measured in Barrow, Alaska in 2016 on six plant species: Arctophila fulva, Arctagrostis latifolia, Carex aquatilis, Eriophorum angustifolium, Petasites frigidus, and Salix pulchra. Version 2 (V2) note (01 Feb 2021): An earlier version of this data contained an incorrectly labeled data column in NGA175_AQfittedParams_Barrow_2016.csv. Mean_Ci was incorrectly labeled as Mean_Ci_LowLight. \"_v2\" contains the correct data for both of these variables. In December 2020, these data were updated to comply with the leaf-level gas exchange data and metadata reporting format (Ely et al 2020, doi:10.15485/1659484). These updates involved editing of some variable names, change of file formats to csv, addition of AQ curves data (subset of complete instrument output included in the original data package) and inclusion of additional methods and instrument details metadata files. No changes were made to the data. The package includes six *.csv files and one *.pdf. The Next-Generation Ecosystem Experiments: Arctic (NGEE Arctic), was a 10-year research effort (2012-2022) to reduce uncertainty in Earth System Models by developing a predictive understanding of carbon-rich Arctic ecosystems and feedbacks to climate. NGEE Arctic was supported by the Department of Energy\\'s Office of Biological and Environmental Research. The NGEE Arctic project had two field research sites: 1) located within the Arctic polygonal tundra coastal region on the Barrow Environmental Observatory (BEO) and the North Slope near Utqiagvik (Barrow), Alaska and 2) multiple areas on the discontinuous permafrost region of the Seward Peninsula north of Nome, Alaska. Through observations, experiments, and synthesis with existing datasets, NGEE Arctic provided an enhanced knowledge base for multi-scale modeling and contributed to improved process representation at global pan-Arctic scales within the Department of Energy\\'s Earth system Model (the Energy Exascale Earth System Model, or E3SM), and specifically within the E3SM Land Model component (ELM).',\n",
              "    'datePublished': '2019'}},\n",
              "  {'id': 'ess-dive-8fce7d96f84db85-20230607T210824521467',\n",
              "   'viewUrl': 'https://data.ess-dive.lbl.gov/view/doi:10.5440/1778212',\n",
              "   'url': 'https://api.ess-dive.lbl.gov/packages/ess-dive-8fce7d96f84db85-20230607T210824521467',\n",
              "   'next': None,\n",
              "   'previous': 'https://api.ess-dive.lbl.gov/packages/ess-dive-841e08015f28c15-20230406T143716608201',\n",
              "   'dateUploaded': '2023-06-07T21:08:25.466Z',\n",
              "   'dateModified': '2024-07-24T18:58:18.933Z',\n",
              "   'isPublic': True,\n",
              "   'citation': 'Serbin S; Yang D; McMahon A (2021): Landscape-scale Characterization of Arctic Tundra Vegetation Composition, Structure, and Function with a Multi-sensor Unoccupied Aerial System: Supporting Data.. Next-Generation Ecosystem Experiments (NGEE) Arctic. Dataset. doi:10.5440/1778212',\n",
              "   'dataset': {'@context': 'http://schema.org/',\n",
              "    '@type': 'Dataset',\n",
              "    '@id': 'doi:10.5440/1778212',\n",
              "    'name': 'Landscape-scale Characterization of Arctic Tundra Vegetation Composition, Structure, and Function with a Multi-sensor Unoccupied Aerial System: Supporting Data.',\n",
              "    'description': \"Airborne remote sensing data collected using the Brookhaven National Laboratory's (BNL) heavy-lift unoccupied aerial system (UAS) octocopter platform, the Osprey, operated by the Terrestrial Ecosystem Science and Technology (TEST) group (https://www.bnl.gov/testgroup). This package includes data from three flights flown over the NGEE-Arctic Council, Kougarok and Teller sites in July, 2018. The Osprey is a multi-sensor UAS platform that simultaneously measures very high spatial resolution optical red/green/blue (RGB) and thermal infrared (TIR) surface 'skin' temperature imagery, as well as surface reflectance at 1 nm intervals in the visible to near-infrared spectral range 350 - 1000 nm measured at regular intervals along each flight path. Derived image products include ortho-mosaiced RGB and TIR images, an RGB-based digital surface model (DSM) using the structure from motion (SfM) technique, digital terrain model (DTM), and a canopy height model (CHM). In addition, a VNIR surface reflectance file is provided for the trigger locations collected during each flight campaign. Ancillary aircraft data, flight mission parameters, and general flight conditions provided by the onboard flight and data collection computers are also included. Unprocessed and processed data products are included in this package (processing levels 0-3). Data and metadata are provided as text (*.txt, *.json, *.kml, *hdr, *.enp), tabular (*.dat, *.csv, *.waypoint, ENVI format (no extension)), point cloud (*.laz) and image (*.jpg, *.tif, *png) formats. This metadata document contains flight campaign, instrument and file metadata, along with a description of data processing levels, data products and file naming scheme.The Next-Generation Ecosystem Experiments: Arctic (NGEE Arctic), a research effort to reduce uncertainty in Earth System Models by developing a predictive understanding of carbon-rich Arctic ecosystems and feedbacks to climate. NGEE Arctic was supported by the Department of Energy?s Office of Biological and Environmental Research.The NGEE Arctic project had two field research sites: 1) located within the Arctic polygonal tundra coastal region on the Barrow Environmental Observatory (BEO) and the North Slope near Utqiagvik (Barrow), Alaska and 2) multiple areas on the discontinuous permafrost region of the Seward Peninsula north of Nome, Alaska.Through observations, experiments, and synthesis with existing datasets, NGEE Arctic provided an enhanced knowledge base for multi-scale modeling and contributed to improved process representation at global pan-Arctic scales within the Department of Energy's Earth system Model (the Energy Exascale Earth System Model, or E3SM), and specifically within the E3SM Land Model component (ELM).\",\n",
              "    'datePublished': '2021'}},\n",
              "  {'id': 'ess-dive-c2fa589311e79d7-20230407T144013754846',\n",
              "   'viewUrl': 'https://data.ess-dive.lbl.gov/view/doi:10.5440/1784755',\n",
              "   'url': 'https://api.ess-dive.lbl.gov/packages/ess-dive-c2fa589311e79d7-20230407T144013754846',\n",
              "   'next': None,\n",
              "   'previous': 'https://api.ess-dive.lbl.gov/packages/ess-dive-1a8c45a483f7adc-20230406T161010234293',\n",
              "   'dateUploaded': '2023-04-07T14:40:14.712Z',\n",
              "   'dateModified': '2024-07-24T19:00:06.719Z',\n",
              "   'isPublic': True,\n",
              "   'citation': 'Salmon V; Childs J; Iversen C; Spencer B; Rogers A; Ely K; Serbin S (2021): Vegetation Warming Experiment: 15N Uptake Experiment Water-Extractable Soil Nutrients, Utqiagvik (Barrow), Alaska, 2018. Next-Generation Ecosystem Experiments (NGEE) Arctic. Dataset. doi:10.5440/1784755',\n",
              "   'dataset': {'@context': 'http://schema.org/',\n",
              "    '@type': 'Dataset',\n",
              "    '@id': 'doi:10.5440/1784755',\n",
              "    'name': 'Vegetation Warming Experiment: 15N Uptake Experiment Water-Extractable Soil Nutrients, Utqiagvik (Barrow), Alaska, 2018',\n",
              "    'description': \"This dataset consists of measured water-extractable carbon and nutrients measured on soils collected from warming experiment enclosures and paired control plots. Harvest types include both natural abundance and enriched soils. Vegetation warming chambers (Zero Power) were deployed on the Barrow Environmental Observatory (BEO), Utqiagvik, Alaska. These chambers (Figure 1) consistently elevated air temperatures by approximately 4C using a self-venting system described by Lewin et al (2017). Five chambers were deployed from June 17, 2018 to September 24, 2018 on the BEO within a 1 km2 area centered on 71.275N, -156.641W. Each chamber was co-located with an ambient plot where temperatures were not manipulated on patches of tundra containing the target species Arctagrostis latifolia. An intensive field campaign in late July investigated the impact of warming had on A. latifolia biomass, chemistry, and uptake of 15N labeled ammonia that was injected into the surface soils for one week. Initial measurements were taken on July 21, 2018. Harvest occurred on July 27, 2018. Water-extractable nutrients in soils were measured in July following harvests of A. latifolia plants and underlying soils. Availability of ammonia, nitrate, and phosphate throughout the growing season was measured by extracting nutrients bound to anion and cation binding resins deployed from July through September. Environmental variables (thaw depth, surface soil temperatures, surface soil moisture) were measured. Leaf traits and root traits of A. latifolia were also measured. The data package includes one *.csv data file and one *.pdf user guide.  The Next-Generation Ecosystem Experiments: Arctic (NGEE Arctic), was a research effort to reduce uncertainty in Earth System Models by developing a predictive understanding of carbon-rich Arctic ecosystems and feedbacks to climate. NGEE Arctic was supported by the Department of Energy's Office of Biological and Environmental Research. The NGEE Arctic project had two field research sites: 1) located within the Arctic polygonal tundra coastal region on the Barrow Environmental Observatory (BEO) and the North Slope near Utqiagvik (Barrow), Alaska and 2) multiple areas on the discontinuous permafrost region of the Seward Peninsula north of Nome, Alaska. Through observations, experiments, and synthesis with existing datasets, NGEE Arctic provided an enhanced knowledge base for multi-scale modeling and contributed to improved process representation at global pan-Arctic scales within the Department of Energy's Earth system Model (the Energy Exascale Earth System Model, or E3SM), and specifically within the E3SM Land Model component (ELM).\",\n",
              "    'datePublished': '2021'}},\n",
              "  {'id': 'ess-dive-2f30849b852d19a-20230407T144000185864',\n",
              "   'viewUrl': 'https://data.ess-dive.lbl.gov/view/doi:10.5440/1784752',\n",
              "   'url': 'https://api.ess-dive.lbl.gov/packages/ess-dive-2f30849b852d19a-20230407T144000185864',\n",
              "   'next': None,\n",
              "   'previous': 'https://api.ess-dive.lbl.gov/packages/ess-dive-990eb2a2fbd88c8-20230406T161016737396',\n",
              "   'dateUploaded': '2023-04-07T14:40:01.110Z',\n",
              "   'dateModified': '2024-07-24T19:00:15.361Z',\n",
              "   'isPublic': True,\n",
              "   'citation': 'Salmon V; Childs J; Iversen C; Spencer B; Rogers A; Ely K; Serbin S (2021): Vegetation Warming Experiment: 15N Uptake Experiment Inorganic Nitrogen and Phosphorus on Resins, Utqiagvik (Barrow), Alaska, 2018. Next-Generation Ecosystem Experiments (NGEE) Arctic. Dataset. doi:10.5440/1784752',\n",
              "   'dataset': {'@context': 'http://schema.org/',\n",
              "    '@type': 'Dataset',\n",
              "    '@id': 'doi:10.5440/1784752',\n",
              "    'name': 'Vegetation Warming Experiment: 15N Uptake Experiment Inorganic Nitrogen and Phosphorus on Resins, Utqiagvik (Barrow), Alaska, 2018',\n",
              "    'description': \"This dataset consists of inorganic ammonia, nitrate, and phosphate bound to anion and cation binding resins deployed from July through September 2018 in the surface soils of vegetation warming experiment enclosures and paired control plots.  Vegetation warming chambers (Zero Power) were deployed on the Barrow Environmental Observatory (BEO), Utqiagvik, Alaska. These chambers (Figure 1) consistently elevated air temperatures by approximately 4C using a self-venting system described by Lewin et al (2017). Five chambers were deployed from June 17, 2018 to September 24, 2018 on the BEO within a 1 km2 area centered on 71.275N, -156.641W. Each chamber was co-located with an ambient plot where temperatures were not manipulated on patches of tundra containing the target species Arctagrostis latifolia. An intensive field campaign in late July investigated the impact of warming had on A. latifolia biomass, chemistry, and uptake of 15N labeled ammonia that was injected into the surface soils for one week. Initial measurements were taken on July 21, 2018. Harvest occurred on July 27, 2018. Water-extractable nutrients in soils were measured in July following harvests of A. latifolia plants and underlying soils. Availability of ammonia, nitrate, and phosphate throughout the growing season was measured by extracting nutrients bound to anion and cation binding resins deployed from July through September. Environmental variables (thaw depth, surface soil temperatures, surface soil moisture) were measured. Leaf traits and root traits of A. latifolia were also measured. Included is one *.csv data file and one *.pdf user guide.  The Next-Generation Ecosystem Experiments: Arctic (NGEE Arctic), was a research effort to reduce uncertainty in Earth System Models by developing a predictive understanding of carbon-rich Arctic ecosystems and feedbacks to climate. NGEE Arctic was supported by the Department of Energy's Office of Biological and Environmental Research. The NGEE Arctic project had two field research sites: 1) located within the Arctic polygonal tundra coastal region on the Barrow Environmental Observatory (BEO) and the North Slope near Utqiagvik (Barrow), Alaska and 2) multiple areas on the discontinuous permafrost region of the Seward Peninsula north of Nome, Alaska. Through observations, experiments, and synthesis with existing datasets, NGEE Arctic provided an enhanced knowledge base for multi-scale modeling and contributed to improved process representation at global pan-Arctic scales within the Department of Energy's Earth system Model (the Energy Exascale Earth System Model, or E3SM), and specifically within the E3SM Land Model component (ELM).\",\n",
              "    'datePublished': '2021'}},\n",
              "  {'id': 'ess-dive-4351ffbcaeb70a2-20230406T143613018506',\n",
              "   'viewUrl': 'https://data.ess-dive.lbl.gov/view/doi:10.5440/1575068',\n",
              "   'url': 'https://api.ess-dive.lbl.gov/packages/ess-dive-4351ffbcaeb70a2-20230406T143613018506',\n",
              "   'next': None,\n",
              "   'previous': 'https://api.ess-dive.lbl.gov/packages/ess-dive-1e0b454254fe38a-20230406T112902346029',\n",
              "   'dateUploaded': '2023-04-06T14:36:13.883Z',\n",
              "   'dateModified': '2024-07-24T19:00:32.264Z',\n",
              "   'isPublic': True,\n",
              "   'citation': 'Rogers A; Alldred M; Serbin S (2020): Leaf Carbon and Nitrogen Content, Seward Peninsula, Alaska, 2014. Next-Generation Ecosystem Experiments (NGEE) Arctic. Dataset. doi:10.5440/1575068',\n",
              "   'dataset': {'@context': 'http://schema.org/',\n",
              "    '@type': 'Dataset',\n",
              "    '@id': 'doi:10.5440/1575068',\n",
              "    'name': 'Leaf Carbon and Nitrogen Content, Seward Peninsula, Alaska, 2014',\n",
              "    'description': \"Carbon and nitrogen content of leaves sampled from locations on the Council, Kougarok and Teller roads, Seward Peninsula, Alaska. Species not fully identified in all cases, but include samples from the genera: Alnus, Arctagrostis, Arctophila, Arctostaphylos, Betula, Carex, Eriophorum, Petasites, Picea, Populus, Rubus, Salix, Saxifraga and Vaccinium. Locations along the Council, Kougarok and Teller roads, Seward Peninsula, Alaska. Samples were collected from various locations as part of reconnaissance field work prior to establishment of formal NGEE Arctic study sites between August 22, 2014 and August 24, 2014. There is a single datafile in .csv format.  The Next-Generation Ecosystem Experiments: Arctic (NGEE Arctic), was a research effort to reduce uncertainty in Earth System Models by developing a predictive understanding of carbon-rich Arctic ecosystems and feedbacks to climate. NGEE Arctic was supported by the Department of Energy's Office of Biological and Environmental Research. The NGEE Arctic project had two field research sites: 1) located within the Arctic polygonal tundra coastal region on the Barrow Environmental Observatory (BEO) and the North Slope near Utqiagvik (Barrow), Alaska and 2) multiple areas on the discontinuous permafrost region of the Seward Peninsula north of Nome, Alaska. Through observations, experiments, and synthesis with existing datasets, NGEE Arctic provided an enhanced knowledge base for multi-scale modeling and contributed to improved process representation at global pan-Arctic scales within the Department of Energy's Earth system Model (the Energy Exascale Earth System Model, or E3SM), and specifically within the E3SM Land Model component (ELM).\",\n",
              "    'datePublished': '2020'}}]}"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Optional: display entire response\n",
        "# ===================================\n",
        "display(response_json)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ddb3ec5",
      "metadata": {
        "id": "6ddb3ec5"
      },
      "source": [
        "### 3. Subset search results - Which datasets do we want to explore further?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c1cba50-d0fa-4acd-a2e6-d1811c1230d0",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "8c1cba50-d0fa-4acd-a2e6-d1811c1230d0"
      },
      "source": [
        "<strong><span style=\"color:blue\">Enter INPUT</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "8fc9b10b-b393-451f-aa9c-f5278dad72f6",
      "metadata": {
        "id": "8fc9b10b-b393-451f-aa9c-f5278dad72f6"
      },
      "outputs": [],
      "source": [
        "# pick any that you are interested in\n",
        "record_indices = [2,4,8,9]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfd16dff-2231-4efe-8043-2707c56be5be",
      "metadata": {
        "id": "dfd16dff-2231-4efe-8043-2707c56be5be"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "423c7dce",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "423c7dce",
        "outputId": "ddddf94f-9e84-4528-87ee-1dd8fe9d2958"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: G-LiHT Campaign Leaf Spectral Reflectance and Transmittance, Mar2017: Puerto Rico\n",
            "1: G-LiHT Campaign Leaf Carbon and Nitrogen Content, Mar2017: Puerto Rico\n",
            "2: G-LiHT Campaign Leaf Mass Area and Water Content, Mar2017: Puerto Rico\n",
            "3: G-LiHT Campaign Leaf Sample details & photos, March 2017: Puerto Rico\n"
          ]
        }
      ],
      "source": [
        "datasets = [candidate_datasets[x] for x in record_indices]\n",
        "citations_list = {}\n",
        "for idx, dataset in enumerate(datasets):\n",
        "    print(f\"{idx}: {dataset.get('dataset').get('name')}\")\n",
        "    # grab the citations of the datasets to store for future use - Remember to always cite data sources you use!\n",
        "    citations_list.update({dataset.get('dataset').get('@id') : dataset.get('citation')})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1426dff6-339a-4269-8634-ac5714e8a68c",
      "metadata": {
        "id": "1426dff6-339a-4269-8634-ac5714e8a68c"
      },
      "source": [
        "### Let's also grab the DOI for each dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbc22230-1531-4d6a-8186-1d280c63b271",
      "metadata": {
        "id": "fbc22230-1531-4d6a-8186-1d280c63b271"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "536344ac-e09c-43b3-8725-71a80bcbf3e7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "536344ac-e09c-43b3-8725-71a80bcbf3e7",
        "outputId": "5a9149b1-1a93-400c-dd14-bf7a503c55cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: doi:10.15486/NGT/1495204, G-LiHT Campaign Leaf Spec...\n",
            "1: doi:10.15486/NGT/1905770, G-LiHT Campaign Leaf Carb...\n",
            "2: doi:10.15486/NGT/1495202, G-LiHT Campaign Leaf Mass...\n",
            "3: doi:10.15486/NGT/1781005, G-LiHT Campaign Leaf Samp...\n"
          ]
        }
      ],
      "source": [
        "# Grab the DOIs for our selected datasets\n",
        "\n",
        "total_doi_array = []\n",
        "for idx, dataset in enumerate(datasets):\n",
        "    print(f\"{idx}: {dataset.get('dataset').get('@id')}, {dataset.get('dataset').get('name')[:25]}...\")\n",
        "    total_doi_array.append(dataset.get('dataset').get('@id'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e24b349-93bc-4acf-9199-936488eb88d1",
      "metadata": {
        "id": "2e24b349-93bc-4acf-9199-936488eb88d1"
      },
      "source": [
        "### Great! We found 9 datasets that may be relevant to our science interest - let's move on from Searching for Data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ed274af-d5f7-492d-934f-827d80857c09",
      "metadata": {
        "id": "6ed274af-d5f7-492d-934f-827d80857c09"
      },
      "source": [
        "---\n",
        "# Part 2: Exploring Inside Datasets\n",
        "Let's look inside the datasets we are interested in. <br>\n",
        "Some datasets follow the File Level Metadata Reporting Format and are structured with File Level Metadata (FLMDs) while some are not. Depending on the file structure, we can approach further exploration differently. <br>\n",
        "First, we'll grab the **dataset details**, then we'll see whether the data has **FLMDs** readily available. Then we can try to **explore within the dataset** to see if it is useful for our science interests"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba9c59c8",
      "metadata": {
        "id": "ba9c59c8"
      },
      "source": [
        "### 1. Get dataset details using ESS-DIVE Dataset API\n",
        "\n",
        "Use the ESS-DIVE individual dataset search to get details of the datasets, including its list of files. The results of the above search contain the URLs to retrieve the dataset details in the field: `url`.\n",
        "\n",
        "The `get_dataset_details` method is a helper function that uses the same _requests.get_ from 'Step 1: Enter Search Parameters and make API call'.\n",
        "\n",
        "**See more details for the individual dataset search in the ESS-DIVE package API techincal documentation:** https://api.ess-dive.lbl.gov/#/Dataset/getDataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1addc15e-1771-4822-95d0-09f4578d8b40",
      "metadata": {
        "id": "1addc15e-1771-4822-95d0-09f4578d8b40"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell - Helper Function</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "0e525d2a-37a7-4d7c-af3c-44339d22ccaf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e525d2a-37a7-4d7c-af3c-44339d22ccaf",
        "outputId": "eed00c89-03d7-4b85-ec90-bef558f7260e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function loaded.\n"
          ]
        }
      ],
      "source": [
        "# load this helper function that does the same GET call to the API but for specific files\n",
        "def get_dataset_details(dataset_url):\n",
        "\n",
        "    response_status = None\n",
        "    try:\n",
        "        dataset_response = requests.get(dataset_url, headers={\"Authorization\": f\"Bearer {token}\"})\n",
        "        response_status = dataset_response.status_code\n",
        "    except Exception as e:\n",
        "        print(f\"{dataset.get('dataset').get('name')} did not have a successful return: {e}\")\n",
        "        return None\n",
        "\n",
        "    # If successful response, add to dataset_store\n",
        "    if response_status == 200:\n",
        "            dataset_json = dataset_response.json()['dataset']\n",
        "            print(f\"--- Acquired details for {dataset_json.get('name')}\")\n",
        "            return dataset_json\n",
        "    elif response_status:\n",
        "        print(f\"Response status {response_status}: {dataset_response.text}\")\n",
        "    else:\n",
        "        print(f\"Response status unavailable. Response cannot be interpreted. Debug required.\")\n",
        "    return None\n",
        "print('Function loaded.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2ea358f-7cae-46d8-bfc6-af87b6140061",
      "metadata": {
        "id": "e2ea358f-7cae-46d8-bfc6-af87b6140061"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "69ea70f9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69ea70f9",
        "outputId": "a879dfd4-e43f-4a17-a04a-3452ce1b932a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Acquired details for G-LiHT Campaign Leaf Spectral Reflectance and Transmittance, Mar2017: Puerto Rico\n",
            "--- Acquired details for G-LiHT Campaign Leaf Carbon and Nitrogen Content, Mar2017: Puerto Rico\n",
            "--- Acquired details for G-LiHT Campaign Leaf Mass Area and Water Content, Mar2017: Puerto Rico\n",
            "--- Acquired details for G-LiHT Campaign Leaf Sample details & photos, March 2017: Puerto Rico\n",
            "=====================================\n",
            "Details acquired for 4 datasets.\n"
          ]
        }
      ],
      "source": [
        "# Store the dataset details in a list\n",
        "dataset_details = []\n",
        "\n",
        "for dataset in datasets:\n",
        "    dataset_url = dataset.get('url')\n",
        "    # see details for the get_dataset_details helper method in the cell above\n",
        "    dataset_detail_json = get_dataset_details(dataset_url)\n",
        "    if dataset_detail_json:\n",
        "        dataset_details.append(dataset_detail_json)\n",
        "\n",
        "print(\"=====================================\")\n",
        "print(f\"Details acquired for {len(dataset_details)} datasets.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "522da694",
      "metadata": {
        "id": "522da694"
      },
      "source": [
        "#### ***Optional***: Want to see what the dataset details look like? Select the input the number in the brackets for the index of the dataset you want to see and run the cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "4ded193a",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4ded193a",
        "outputId": "d4b2c607-b6fb-4d83-bf22-74d4e21e18c9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'@context': 'http://schema.org/',\n",
              " '@type': 'Dataset',\n",
              " '@id': 'doi:10.15486/NGT/1781005',\n",
              " 'name': 'G-LiHT Campaign Leaf Sample details & photos, March 2017: Puerto Rico',\n",
              " 'description': ['This data package includes details of leaves sampled for leaf spectra and chemistry from 5 sites in Puerto Rico, in March of 2017. Sunlit canopy and shaded leaves of 66 species were collected. Data for each sample includes species, leaf age, type of analysis (spectroscopy, gas exchange, chemistry), sample number and sample photographs. The data package includes a spreadsheet with sample information and a zip file of photographs (1.6 GB). This data was collected as part of the 2017 BNLG-LiHT leaf spectra campaign. See related datasets for leaf spectral reflectance and transmittance, leaf mass area (LMA), and leaf chemistry. Note that leaf sample details are also included in related datasets.',\n",
              "  'This dataset was originally published on the NGEE Tropics Archive and is being mirrored on ESS-DIVE for long-term archival',\n",
              "  'Acknowledgement: This research was supported as part of NGEE-Tropics, funded by the U.S. Department of Energy, Office of Science, Office of Biological and Environmental Research under contract no. DE-SC0012704.'],\n",
              " 'alternateName': ['http://dx.doi.org/10.15486/ngt/1781005', 'NGT0077'],\n",
              " 'creator': [{'@type': 'Person',\n",
              "   '@id': 'http://orcid.org/0000-0003-4136-8971',\n",
              "   'givenName': 'Shawn',\n",
              "   'familyName': 'Serbin',\n",
              "   'affiliation': 'Brookhaven National Laboratory',\n",
              "   'email': 'sserbin@bnl.gov'},\n",
              "  {'@type': 'Person',\n",
              "   '@id': 'http://orcid.org/0000-0001-8991-3970',\n",
              "   'givenName': 'Jin',\n",
              "   'familyName': 'Wu',\n",
              "   'affiliation': 'University of Hong Kong',\n",
              "   'email': 'jinwu@hku.hk'},\n",
              "  {'@type': 'Person',\n",
              "   'givenName': 'Ran',\n",
              "   'familyName': 'Meng',\n",
              "   'email': 'ranmeng@bnl.gov'},\n",
              "  {'@type': 'Person',\n",
              "   '@id': 'http://orcid.org/0000-0002-3915-001X',\n",
              "   'givenName': 'Kim',\n",
              "   'familyName': 'Ely',\n",
              "   'affiliation': 'Lawrence Berkeley National Laboratory',\n",
              "   'email': 'ksely@lbl.gov'}],\n",
              " 'datePublished': '2021-05-04',\n",
              " 'keywords': ['Next-Generation Ecosystem Experiements Tropics',\n",
              "  'NGEE-T',\n",
              "  'ESS-DIVE Location Metadata Reporting Format'],\n",
              " 'variableMeasured': ['Leaf phenology'],\n",
              " 'license': 'http://creativecommons.org/licenses/by/4.0/',\n",
              " 'spatialCoverage': [{'@type': 'Place',\n",
              "   'description': 'Site Name: CAM2: Cambalache State Forest. Site ID: PR-CAM. Located in Puerto Rico. Old growh forest (>80 yrs old) in Cambalache State Forest. Site contact(s): (Maria Uriarte <mu2126@columbia.edu>)',\n",
              "   'geo': [{'@type': 'GeoCoordinates',\n",
              "     'name': 'Northwest',\n",
              "     'latitude': 18.450039,\n",
              "     'longitude': -66.600936},\n",
              "    {'@type': 'GeoCoordinates',\n",
              "     'name': 'Southeast',\n",
              "     'latitude': 18.44989,\n",
              "     'longitude': -66.600312}]},\n",
              "  {'@type': 'Place',\n",
              "   'description': 'Site Name: CAR1: Carite State Forest. Site ID: PR-CAR. Located in Puerto Rico. Old growh forest (>80 yrs old) in Carite State Forest. Site contact(s): (Maria Uriarte <mu2126@columbia.edu>)',\n",
              "   'geo': [{'@type': 'GeoCoordinates',\n",
              "     'name': 'Northwest',\n",
              "     'latitude': 18.093127,\n",
              "     'longitude': -66.029806},\n",
              "    {'@type': 'GeoCoordinates',\n",
              "     'name': 'Southeast',\n",
              "     'latitude': 18.092714,\n",
              "     'longitude': -66.029283}]},\n",
              "  {'@type': 'Place',\n",
              "   'description': 'Site Name: Fundacion Luis Munoz Marin (FLMM). Site ID: PR-FLM. A botanical garden in San Juan, Puerto RicoArboretum Parque Dona InesFundacion Luis Munoz MarinRR 2, Box #5San JuanPR 00926-9766 Puerto RicoTelephone: (787) 755-7979Fax: URL: http://luismunozmarin.net/flmm/flmm-parque-dona-inesPrimary Email: ctorres@flmm.org For more information on this site, visit: http://www.bgci.org/garden.php?id=5001 http://luismunozmarin.net/flmm/flmm-parque-dona-ines Site contact(s): (Christian W. Torres Santana <ctorres@flmm.org>)',\n",
              "   'geo': [{'@type': 'GeoCoordinates',\n",
              "     'name': 'Northwest',\n",
              "     'latitude': 18.387532,\n",
              "     'longitude': -66.028537},\n",
              "    {'@type': 'GeoCoordinates',\n",
              "     'name': 'Southeast',\n",
              "     'latitude': 18.387532,\n",
              "     'longitude': -66.028537}]},\n",
              "  {'@type': 'Place',\n",
              "   'description': 'Site Name: SB2: Sabana 2. Site ID: PR-SB2. Located in Puerto Rico. Young secondary forest in an area immediately adjacent to an old teak plantation forest near the Sabana field station. Site contact(s): (Maria Uriarte <mu2126@columbia.edu>)',\n",
              "   'geo': [{'@type': 'GeoCoordinates',\n",
              "     'name': 'Northwest',\n",
              "     'latitude': 18.322428,\n",
              "     'longitude': -65.731279},\n",
              "    {'@type': 'GeoCoordinates',\n",
              "     'name': 'Southeast',\n",
              "     'latitude': 18.322287,\n",
              "     'longitude': -65.730283}]},\n",
              "  {'@type': 'Place',\n",
              "   'description': 'Site Name: International Institute of Tropical Forestry. Site ID: PR-UPR. This location is also known as the botanical garden at the University of Puerto Rico (Jardn Botnico de la UPR)https://www.fs.usda.gov/iitf Site contact(s): (Grizelle Gonzlez <ggonzalez@fs.fed.us>)',\n",
              "   'geo': [{'@type': 'GeoCoordinates',\n",
              "     'name': 'Northwest',\n",
              "     'latitude': 18.38923,\n",
              "     'longitude': -66.05525},\n",
              "    {'@type': 'GeoCoordinates',\n",
              "     'name': 'Southeast',\n",
              "     'latitude': 18.38923,\n",
              "     'longitude': -66.05525}]}],\n",
              " 'award': ['DE-AC02-05CH11231', 'DE-SC0012704'],\n",
              " 'funder': [{'@type': 'Organization',\n",
              "   'name': 'U.S. DOE > Office of Science > Biological and Environmental Research (BER)'}],\n",
              " 'temporalCoverage': {'startDate': '2017-03-03',\n",
              "  'endDate': '2017-03-09',\n",
              "  '@type': 'DateTime'},\n",
              " 'editor': {'@type': 'Person',\n",
              "  '@id': 'http://orcid.org/0000-0003-4136-8971',\n",
              "  'givenName': 'Shawn',\n",
              "  'familyName': 'Serbin',\n",
              "  'affiliation': 'Brookhaven National Laboratory',\n",
              "  'email': 'sserbin@bnl.gov'},\n",
              " 'provider': {'@type': 'Organization',\n",
              "  'identifier': {'@type': 'PropertyValue',\n",
              "   'propertyID': 'ess-dive',\n",
              "   'value': 'a441fe85-5ac3-41b1-bbe5-46df92682609'},\n",
              "  'name': 'Next-Generation Ecosystem Experiments (NGEE) Tropics',\n",
              "  'member': {'@type': 'Person',\n",
              "   'givenName': 'Jeffrey',\n",
              "   'familyName': 'Chambers',\n",
              "   'jobTitle': 'Principal Investigator',\n",
              "   'affiliation': 'Lawrence Berkeley National Laboratory',\n",
              "   'email': 'jchambers@lbl.gov'}},\n",
              " 'measurementTechnique': ['Sample details were recorded at the time of field sampling. Leaf samples were photographed with unique SampleID label. Species were identified either using existing, previously identified trees or by later conducting species identification based on sample vouchers. Sample records were cross checked against other related datasets (NGT0078, 79) for consistency of species, sample data and site.'],\n",
              " 'distribution': [{'contentSize': 1.9296875,\n",
              "   'contentUrl': 'https://data.ess-dive.lbl.gov/catalog/d1/mn/v2/object/ess-dive-1e92402c98110a3-20240913T175522805088',\n",
              "   'encodingFormat': 'text/csv',\n",
              "   'identifier': 'ess-dive-1e92402c98110a3-20240913T175522805088',\n",
              "   'name': 'NGT0077_locations.csv'},\n",
              "  {'contentSize': 9.6533203125,\n",
              "   'contentUrl': 'https://data.ess-dive.lbl.gov/catalog/d1/mn/v2/object/ess-dive-bf58a2ab1d40f9f-20241028T151709835342',\n",
              "   'encodingFormat': 'https://eml.ecoinformatics.org/eml-2.2.0',\n",
              "   'identifier': 'ess-dive-bf58a2ab1d40f9f-20241028T151709835342',\n",
              "   'name': 'G_LiHT_Campaign_Leaf_Sample_details_photos_March_2017_Puerto_Rico.xml'},\n",
              "  {'contentSize': 1592864.58203125,\n",
              "   'contentUrl': 'https://data.ess-dive.lbl.gov/catalog/d1/mn/v2/object/ess-dive-a421d695ce279f7-20220608T192417400244',\n",
              "   'encodingFormat': 'application/zip',\n",
              "   'identifier': 'ess-dive-a421d695ce279f7-20220608T192417400244',\n",
              "   'name': 'NGT0077_PR2017samples_20200923222634_20200923222634.zip'}]}"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Optional: Run to display dataset information for one of the datasets you chose - you can change number in the brackets to select\n",
        "#index is based on # of data sets- in this example it would be 0-3\n",
        "# ===================================\n",
        "display(dataset_details[3])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d739c67e",
      "metadata": {
        "id": "d739c67e"
      },
      "source": [
        "### 2. Which datasets have File Level Metadata (FLMD)?\n",
        "Some datasets are structured with FLMDs and some are not. Depending on the file structure, we can approach further exploration differently.\n",
        "\n",
        "#### Here is a helper function `assess_datasets_flmd_dd_csv_files` that will inspect a list of datasets and search the files in a dataset for `flmd` files. It will return two lists of datasets - one for datasets that have a readily accessible FLMD (not in a zip file) and ones that do not (either no FLMD or it is in a zip file).\n",
        "The utility of this function allows us to get a sense of which tools may be the most helpful in determining if a dataset will be useful."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1263a41-a04c-4ad3-ae9c-2693d8060979",
      "metadata": {
        "id": "c1263a41-a04c-4ad3-ae9c-2693d8060979"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell - Helper Function</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "4101a071-68b8-42fd-8890-dc0d15574440",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4101a071-68b8-42fd-8890-dc0d15574440",
        "outputId": "507d585d-759b-482f-ec9b-2d9a90379a45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function loaded.\n"
          ]
        }
      ],
      "source": [
        "def assess_datasets_flmd_dd_csv_files(dataset_details_list):\n",
        "    \"\"\"\n",
        "    Find the datasets with flmd files\n",
        "    Sort the csv file contents into potential and data files; add to the dataset details dictionary\n",
        "    \"\"\"\n",
        "    flmd_datasets_indices = set()\n",
        "    flmd_dataset_details = []\n",
        "\n",
        "    for idx, dataset in enumerate(dataset_details_list):\n",
        "        file_list = dataset.get('distribution')\n",
        "        flmd_url = {}\n",
        "        csv_files = {}\n",
        "        for f in file_list:\n",
        "            encoding_format = f.get('encodingFormat')\n",
        "            filename = f.get('name')\n",
        "            url = f.get('contentUrl')\n",
        "\n",
        "            if 'csv' not in encoding_format or url is None:\n",
        "                continue\n",
        "            if 'flmd' in filename:\n",
        "                flmd_datasets_indices.add(idx)\n",
        "                flmd_url.update({filename: url})\n",
        "            else:\n",
        "                csv_files.update({filename: url})\n",
        "\n",
        "        dataset.update({\n",
        "            'flmd_url': flmd_url,\n",
        "            'csv_files': csv_files\n",
        "        })\n",
        "\n",
        "        if not flmd_url:\n",
        "            dataset_name = dataset.get('name')\n",
        "            print(f\"No flmd found for dataset: {dataset_name}\")\n",
        "\n",
        "    print(\"=====================================\")\n",
        "    if len(flmd_datasets_indices) > 0:\n",
        "        print(f'flmd found in {len(flmd_datasets_indices)} datasets')\n",
        "        flmd_dataset_details = [dataset_details_list[x] for x in flmd_datasets_indices]\n",
        "    else:\n",
        "        print(f'No datasets in the search results have flmds.')\n",
        "\n",
        "    no_flmd_dataset_details = [dataset_detail for idx, dataset_detail in enumerate(dataset_details_list) if idx not in flmd_datasets_indices]\n",
        "    return flmd_dataset_details, no_flmd_dataset_details\n",
        "print('Function loaded.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d127156c-5a7f-4c82-9b6d-3ee8b04708e3",
      "metadata": {
        "id": "d127156c-5a7f-4c82-9b6d-3ee8b04708e3"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "27036b02",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27036b02",
        "outputId": "8885b680-3f7b-4a03-f07e-e2096b901632"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No flmd found for dataset: G-LiHT Campaign Leaf Spectral Reflectance and Transmittance, Mar2017: Puerto Rico\n",
            "No flmd found for dataset: G-LiHT Campaign Leaf Carbon and Nitrogen Content, Mar2017: Puerto Rico\n",
            "No flmd found for dataset: G-LiHT Campaign Leaf Mass Area and Water Content, Mar2017: Puerto Rico\n",
            "No flmd found for dataset: G-LiHT Campaign Leaf Sample details & photos, March 2017: Puerto Rico\n",
            "=====================================\n",
            "No datasets in the search results have flmds.\n"
          ]
        }
      ],
      "source": [
        "# use the helper function assess_datasets_flmd_dd_csv_files to determine which files have readily accessible flmd\n",
        "flmd_datasets, no_flmd_datasets = assess_datasets_flmd_dd_csv_files(dataset_details)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96135178-234b-4b3d-ae77-b01cf855b9d3",
      "metadata": {
        "id": "96135178-234b-4b3d-ae77-b01cf855b9d3"
      },
      "source": [
        "## A. Manually inspect the FLMD and Data Dictionary (DD)\n",
        "This section manually examines structured data (FLMD) through FLMD and DD, which may be useful for a variety of purposes. An alternative approach would be to use the DeepDive API, but here we can look a files that are not in the Fusion database (and therefore not parseable by DeepDive).  <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a825e83b",
      "metadata": {
        "id": "a825e83b"
      },
      "source": [
        "### 3. Choose dataset to inspect - from datasets with accessible FLMD"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cec267c4-c56e-4be0-840a-17fea8dd5b7f",
      "metadata": {
        "id": "cec267c4-c56e-4be0-840a-17fea8dd5b7f"
      },
      "source": [
        "<strong><span style=\"color:blue\">Enter INPUT</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "054bce5a-c00a-48da-91cb-736b74445388",
      "metadata": {
        "id": "054bce5a-c00a-48da-91cb-736b74445388"
      },
      "outputs": [],
      "source": [
        "# Write in the index of the FLMD dataset you want to investigate\n",
        "ds_idx = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b47009de-68a2-4379-ac70-31a77469ce92",
      "metadata": {
        "id": "b47009de-68a2-4379-ac70-31a77469ce92"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell - Helper Function and Print</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "fd22c8f8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "fd22c8f8",
        "outputId": "9c742643-7ffd-4ff5-b2d4-1047f0652490"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-d2d4ecc1c11d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflmd_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mds_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# helper function to print the dataset information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_dataset_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo_fields\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'@id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'description'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'citation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_space\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\" \n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "dataset = flmd_datasets[ds_idx]\n",
        "\n",
        "# helper function to print the dataset information\n",
        "def print_dataset_info(d, info_fields=['@id', 'name', 'description', 'citation'], line_space=False):\n",
        "    \"\"\"\n",
        "    Display basic dataset info for evaluation\n",
        "    \"\"\"\n",
        "    for f in info_fields:\n",
        "        value = d.get(f)\n",
        "        if value is None:\n",
        "            dataset_value = d.get('dataset')\n",
        "            if dataset_value:\n",
        "                value = dataset_value.get(f)\n",
        "        if value:\n",
        "            if f in ['flmd_url', 'csv_files']:\n",
        "                print(f\"--- {f}:\")\n",
        "                for filename, url in value.items():\n",
        "                    print(f\"    - {filename}\")\n",
        "                continue\n",
        "            print(f\"--- {f}: {value}\")\n",
        "            if line_space:\n",
        "                print(\" \")\n",
        "\n",
        "print_dataset_info(dataset, info_fields=['@id', 'name', 'flmd_url'], line_space=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8aea0c9",
      "metadata": {
        "id": "b8aea0c9"
      },
      "source": [
        "### 4. Select and read flmd\n",
        "\n",
        "_If multiple flmd files exist in the dataset, run the cell below as many times as needed changing the index._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43f74af9-61f0-4be7-a0bd-2d061b863c5a",
      "metadata": {
        "id": "43f74af9-61f0-4be7-a0bd-2d061b863c5a"
      },
      "source": [
        "<strong><span style=\"color:blue\">Enter INPUT</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e3d941e-f69e-4f19-ab9c-99b2eeb2aae1",
      "metadata": {
        "id": "4e3d941e-f69e-4f19-ab9c-99b2eeb2aae1"
      },
      "outputs": [],
      "source": [
        "# Select index of the FLMD you want to use\n",
        "flmd_file_idx = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd0ef402-c79a-44a6-8363-9aadd1c2a446",
      "metadata": {
        "id": "dd0ef402-c79a-44a6-8363-9aadd1c2a446"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e546ae3",
      "metadata": {
        "id": "2e546ae3"
      },
      "outputs": [],
      "source": [
        "# read the flmd\n",
        "flmd_name, flmd_url = list(dataset.get('flmd_url').items())[flmd_file_idx]\n",
        "print(f\"{flmd_name}: {flmd_url}\")\n",
        "print('-------------------------')\n",
        "\n",
        "flmd_response = get_request(flmd_name, flmd_url)\n",
        "\n",
        "flmd_headers, flmd_store = make_store(flmd_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3aa50ff",
      "metadata": {
        "id": "a3aa50ff"
      },
      "source": [
        "### 5. View dataset files listed in flmd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "003d4d65-7c56-4f4c-886e-5f476a0b567f",
      "metadata": {
        "id": "003d4d65-7c56-4f4c-886e-5f476a0b567f"
      },
      "source": [
        "<strong><span style=\"color:blue\">Enter INPUT</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f72e3d01-7154-4c7c-9fa3-3178853362ba",
      "metadata": {
        "id": "f72e3d01-7154-4c7c-9fa3-3178853362ba"
      },
      "outputs": [],
      "source": [
        "# Enter flmd fields to view (File name automatically included):\n",
        "flmd_header_indices = [1, -2]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1238a81e-0029-4d0c-b11f-cbc3a15233b4",
      "metadata": {
        "id": "1238a81e-0029-4d0c-b11f-cbc3a15233b4"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68b1b21d",
      "metadata": {
        "scrolled": true,
        "id": "68b1b21d"
      },
      "outputs": [],
      "source": [
        "# print dataset files in flmd\n",
        "for idx, flmd_info in flmd_store.items():\n",
        "    print(f\"{idx}: {flmd_info.get(flmd_headers[0])}\")\n",
        "    for flmd_idx in flmd_header_indices:\n",
        "        print(f\"-- {flmd_headers[flmd_idx]}: {flmd_info.get(flmd_headers[flmd_idx])}\")\n",
        "    print(f\"---------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad2d45fa",
      "metadata": {
        "id": "ad2d45fa"
      },
      "source": [
        "### 6. Inspect dataset file contents using Data Dictionary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00808449-401b-4ada-a064-688dadd8fba6",
      "metadata": {
        "id": "00808449-401b-4ada-a064-688dadd8fba6"
      },
      "source": [
        "<strong><span style=\"color:blue\">Enter INPUT</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f590572-cb16-4fa9-9d4b-7f9a7e43c180",
      "metadata": {
        "id": "5f590572-cb16-4fa9-9d4b-7f9a7e43c180"
      },
      "outputs": [],
      "source": [
        "# Enter data file index\n",
        "data_file_index = 10\n",
        "\n",
        "# Enter Data Dictionary file index\n",
        "dd_file_index = 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2522a55-4b2c-4046-be2a-e22121dd8452",
      "metadata": {
        "id": "b2522a55-4b2c-4046-be2a-e22121dd8452"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8539c6bd",
      "metadata": {
        "id": "8539c6bd"
      },
      "outputs": [],
      "source": [
        "# Grab the DD\n",
        "dd_file_name = flmd_store[f\"Index {dd_file_index}\"].get('File_Name')\n",
        "data_file_name = flmd_store[f\"Index {data_file_index}\"].get('File_Name')\n",
        "print(f'Data File: {data_file_name}\\n'\n",
        "      f'Data Dictionary File: {dd_file_name}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57998e82-68d9-4740-ad71-30142c4c5c9c",
      "metadata": {
        "id": "57998e82-68d9-4740-ad71-30142c4c5c9c"
      },
      "source": [
        "### 7. Check if the DD is zipped"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1c989fb-204e-4f48-a80c-f7e5ca781f78",
      "metadata": {
        "id": "f1c989fb-204e-4f48-a80c-f7e5ca781f78"
      },
      "source": [
        "<strong><span style=\"color:blue\">Enter INPUT</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bc68277-cf57-4335-b4a9-6548ccc4ec93",
      "metadata": {
        "id": "1bc68277-cf57-4335-b4a9-6548ccc4ec93"
      },
      "outputs": [],
      "source": [
        "# choose which files you want to print out that are included in the dataset\n",
        "file_type = 'all'  # 'all' or 'csv' or 'pdf' or 'zip'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0718f362-0b10-4567-94f3-5f85234105a2",
      "metadata": {
        "id": "0718f362-0b10-4567-94f3-5f85234105a2"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd823107-4b42-40b5-9dab-9d39e1e7f8e1",
      "metadata": {
        "scrolled": true,
        "id": "bd823107-4b42-40b5-9dab-9d39e1e7f8e1"
      },
      "outputs": [],
      "source": [
        "# helper function that lists the files included\n",
        "inspect_dataset_distribution(dataset, file_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ae892df-4871-4286-b733-09bc6803d2ea",
      "metadata": {
        "id": "8ae892df-4871-4286-b733-09bc6803d2ea"
      },
      "source": [
        "### 8A) IF DD in zip: search in zip for DD"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24e7920b-0414-4aa8-9250-527baef59668",
      "metadata": {
        "id": "24e7920b-0414-4aa8-9250-527baef59668"
      },
      "source": [
        "#### 1. Show zip contents to select DD"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "825971f2-81f9-4eb1-a6f3-e220f32a029e",
      "metadata": {
        "id": "825971f2-81f9-4eb1-a6f3-e220f32a029e"
      },
      "source": [
        "<strong><span style=\"color:blue\">Enter INPUT</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a19ddbe0-69ac-486e-b07e-5dc0d43d6bea",
      "metadata": {
        "id": "a19ddbe0-69ac-486e-b07e-5dc0d43d6bea"
      },
      "outputs": [],
      "source": [
        "# file from file distribution - choose the zip where you think the DD may be\n",
        "zip_file_idx = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c75275a5-39cf-47bd-b226-3eff95d5a655",
      "metadata": {
        "id": "c75275a5-39cf-47bd-b226-3eff95d5a655"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47ef887f-b749-4cf5-9078-ca0e18375d90",
      "metadata": {
        "scrolled": true,
        "id": "47ef887f-b749-4cf5-9078-ca0e18375d90"
      },
      "outputs": [],
      "source": [
        "# helper function that prints zipped file content\n",
        "fn, zip_download = inspect_zip_file_contents(dataset, zip_file_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe0de4c2-e3c8-4de6-96f0-90c28d771379",
      "metadata": {
        "id": "fe0de4c2-e3c8-4de6-96f0-90c28d771379"
      },
      "source": [
        "#### 2. Display DD within zip file to inspect"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54fe6165-070f-4b12-bb5b-1cb4e1821b1c",
      "metadata": {
        "id": "54fe6165-070f-4b12-bb5b-1cb4e1821b1c"
      },
      "source": [
        "<strong><span style=\"color:blue\">Enter INPUT</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4121e5d6-a88f-4e77-8927-8678c2b20e1b",
      "metadata": {
        "id": "4121e5d6-a88f-4e77-8927-8678c2b20e1b"
      },
      "outputs": [],
      "source": [
        "# Run if csv file is zipped up\n",
        "dd_csv = 1\n",
        "\n",
        "# If needed adjust the number of rows to skip.\n",
        "header_rows = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14a0aee3-5537-467c-a206-66d233632e57",
      "metadata": {
        "id": "14a0aee3-5537-467c-a206-66d233632e57"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edc7e785-30db-4239-9ae1-b331039a065d",
      "metadata": {
        "scrolled": true,
        "id": "edc7e785-30db-4239-9ae1-b331039a065d"
      },
      "outputs": [],
      "source": [
        "\n",
        "csv_file_name = zip_download.namelist()[dd_csv]\n",
        "print(f'Attempting to read: {csv_file_name} from zip file {fn}')\n",
        "\n",
        "metadata_df = read_zipped_csv(zip_download, csv_file_name, header_rows)\n",
        "zip_download_dd = zip_download\n",
        "fn_dd = fn\n",
        "\n",
        "if metadata_df is not None:\n",
        "    is_csv_zipped = True\n",
        "    headers = list(metadata_df.columns)\n",
        "    display(metadata_df)\n",
        "else:\n",
        "    print('ERROR: Sample metadata file was not successfully loaded.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "737c5bfe",
      "metadata": {
        "id": "737c5bfe"
      },
      "source": [
        "### 8B) If DD not in zip: Inspect data dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e638fcd5",
      "metadata": {
        "id": "e638fcd5"
      },
      "outputs": [],
      "source": [
        "# ===================================\n",
        "data_files = dataset.get('csv_files')\n",
        "\n",
        "if dd_file_name not in data_files.keys():\n",
        "    print(f\"Cannot find {dd_file_name} in dataset distribution.\")\n",
        "else:\n",
        "    dd_url = data_files[dd_file_name]\n",
        "    print(f\"{dd_file_name}\")\n",
        "    print(f\"{dd_url}\")\n",
        "    print('-------------------------')\n",
        "\n",
        "    dd_request = get_request(dd_file_name, dd_url)\n",
        "    dd_headers, dd_store = make_store(dd_request)\n",
        "    print('-------------------------')\n",
        "\n",
        "    for idx, dd_info in dd_store.items():\n",
        "        print(f\"{dd_info.get(dd_headers[0])} -- Units: {dd_info.get(dd_headers[1])} -- Desc: {dd_info.get(dd_headers[2])}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a26d18d1-0fbb-4fca-bc88-d5d6caa8b683",
      "metadata": {
        "id": "a26d18d1-0fbb-4fca-bc88-d5d6caa8b683"
      },
      "source": [
        "## B. No FLMD or DD? No problem! We can look inside the datasets manually with the Dataset Details\n",
        "_Inspect dataset using Dataset Details Distribution_ <br>\n",
        "Useful for a preliminary search into files without readily accessible FLMDs. You may find FLMDs and DDs stored within the zip, but let's start without them."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35a3e547",
      "metadata": {
        "id": "35a3e547"
      },
      "source": [
        "### 9. Choose dataset to inspect using index above from the non-FLMD list."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "817d1254-c22a-4b00-a0e3-f7ab1f847360",
      "metadata": {
        "id": "817d1254-c22a-4b00-a0e3-f7ab1f847360"
      },
      "source": [
        "<strong><span style=\"color:blue\">Enter INPUT</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "bc765356-8c5e-4d57-abb3-f43b9f86ff99",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc765356-8c5e-4d57-abb3-f43b9f86ff99",
        "outputId": "3c2ed00b-3326-46f3-83fb-ab70d4130a9e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'@context': 'http://schema.org/',\n",
              " '@type': 'Dataset',\n",
              " '@id': 'doi:10.15486/NGT/1781005',\n",
              " 'name': 'G-LiHT Campaign Leaf Sample details & photos, March 2017: Puerto Rico',\n",
              " 'description': ['This data package includes details of leaves sampled for leaf spectra and chemistry from 5 sites in Puerto Rico, in March of 2017. Sunlit canopy and shaded leaves of 66 species were collected. Data for each sample includes species, leaf age, type of analysis (spectroscopy, gas exchange, chemistry), sample number and sample photographs. The data package includes a spreadsheet with sample information and a zip file of photographs (1.6 GB). This data was collected as part of the 2017 BNLG-LiHT leaf spectra campaign. See related datasets for leaf spectral reflectance and transmittance, leaf mass area (LMA), and leaf chemistry. Note that leaf sample details are also included in related datasets.',\n",
              "  'This dataset was originally published on the NGEE Tropics Archive and is being mirrored on ESS-DIVE for long-term archival',\n",
              "  'Acknowledgement: This research was supported as part of NGEE-Tropics, funded by the U.S. Department of Energy, Office of Science, Office of Biological and Environmental Research under contract no. DE-SC0012704.'],\n",
              " 'alternateName': ['http://dx.doi.org/10.15486/ngt/1781005', 'NGT0077'],\n",
              " 'creator': [{'@type': 'Person',\n",
              "   '@id': 'http://orcid.org/0000-0003-4136-8971',\n",
              "   'givenName': 'Shawn',\n",
              "   'familyName': 'Serbin',\n",
              "   'affiliation': 'Brookhaven National Laboratory',\n",
              "   'email': 'sserbin@bnl.gov'},\n",
              "  {'@type': 'Person',\n",
              "   '@id': 'http://orcid.org/0000-0001-8991-3970',\n",
              "   'givenName': 'Jin',\n",
              "   'familyName': 'Wu',\n",
              "   'affiliation': 'University of Hong Kong',\n",
              "   'email': 'jinwu@hku.hk'},\n",
              "  {'@type': 'Person',\n",
              "   'givenName': 'Ran',\n",
              "   'familyName': 'Meng',\n",
              "   'email': 'ranmeng@bnl.gov'},\n",
              "  {'@type': 'Person',\n",
              "   '@id': 'http://orcid.org/0000-0002-3915-001X',\n",
              "   'givenName': 'Kim',\n",
              "   'familyName': 'Ely',\n",
              "   'affiliation': 'Lawrence Berkeley National Laboratory',\n",
              "   'email': 'ksely@lbl.gov'}],\n",
              " 'datePublished': '2021-05-04',\n",
              " 'keywords': ['Next-Generation Ecosystem Experiements Tropics',\n",
              "  'NGEE-T',\n",
              "  'ESS-DIVE Location Metadata Reporting Format'],\n",
              " 'variableMeasured': ['Leaf phenology'],\n",
              " 'license': 'http://creativecommons.org/licenses/by/4.0/',\n",
              " 'spatialCoverage': [{'@type': 'Place',\n",
              "   'description': 'Site Name: CAM2: Cambalache State Forest. Site ID: PR-CAM. Located in Puerto Rico. Old growh forest (>80 yrs old) in Cambalache State Forest. Site contact(s): (Maria Uriarte <mu2126@columbia.edu>)',\n",
              "   'geo': [{'@type': 'GeoCoordinates',\n",
              "     'name': 'Northwest',\n",
              "     'latitude': 18.450039,\n",
              "     'longitude': -66.600936},\n",
              "    {'@type': 'GeoCoordinates',\n",
              "     'name': 'Southeast',\n",
              "     'latitude': 18.44989,\n",
              "     'longitude': -66.600312}]},\n",
              "  {'@type': 'Place',\n",
              "   'description': 'Site Name: CAR1: Carite State Forest. Site ID: PR-CAR. Located in Puerto Rico. Old growh forest (>80 yrs old) in Carite State Forest. Site contact(s): (Maria Uriarte <mu2126@columbia.edu>)',\n",
              "   'geo': [{'@type': 'GeoCoordinates',\n",
              "     'name': 'Northwest',\n",
              "     'latitude': 18.093127,\n",
              "     'longitude': -66.029806},\n",
              "    {'@type': 'GeoCoordinates',\n",
              "     'name': 'Southeast',\n",
              "     'latitude': 18.092714,\n",
              "     'longitude': -66.029283}]},\n",
              "  {'@type': 'Place',\n",
              "   'description': 'Site Name: Fundacion Luis Munoz Marin (FLMM). Site ID: PR-FLM. A botanical garden in San Juan, Puerto RicoArboretum Parque Dona InesFundacion Luis Munoz MarinRR 2, Box #5San JuanPR 00926-9766 Puerto RicoTelephone: (787) 755-7979Fax: URL: http://luismunozmarin.net/flmm/flmm-parque-dona-inesPrimary Email: ctorres@flmm.org For more information on this site, visit: http://www.bgci.org/garden.php?id=5001 http://luismunozmarin.net/flmm/flmm-parque-dona-ines Site contact(s): (Christian W. Torres Santana <ctorres@flmm.org>)',\n",
              "   'geo': [{'@type': 'GeoCoordinates',\n",
              "     'name': 'Northwest',\n",
              "     'latitude': 18.387532,\n",
              "     'longitude': -66.028537},\n",
              "    {'@type': 'GeoCoordinates',\n",
              "     'name': 'Southeast',\n",
              "     'latitude': 18.387532,\n",
              "     'longitude': -66.028537}]},\n",
              "  {'@type': 'Place',\n",
              "   'description': 'Site Name: SB2: Sabana 2. Site ID: PR-SB2. Located in Puerto Rico. Young secondary forest in an area immediately adjacent to an old teak plantation forest near the Sabana field station. Site contact(s): (Maria Uriarte <mu2126@columbia.edu>)',\n",
              "   'geo': [{'@type': 'GeoCoordinates',\n",
              "     'name': 'Northwest',\n",
              "     'latitude': 18.322428,\n",
              "     'longitude': -65.731279},\n",
              "    {'@type': 'GeoCoordinates',\n",
              "     'name': 'Southeast',\n",
              "     'latitude': 18.322287,\n",
              "     'longitude': -65.730283}]},\n",
              "  {'@type': 'Place',\n",
              "   'description': 'Site Name: International Institute of Tropical Forestry. Site ID: PR-UPR. This location is also known as the botanical garden at the University of Puerto Rico (Jardn Botnico de la UPR)https://www.fs.usda.gov/iitf Site contact(s): (Grizelle Gonzlez <ggonzalez@fs.fed.us>)',\n",
              "   'geo': [{'@type': 'GeoCoordinates',\n",
              "     'name': 'Northwest',\n",
              "     'latitude': 18.38923,\n",
              "     'longitude': -66.05525},\n",
              "    {'@type': 'GeoCoordinates',\n",
              "     'name': 'Southeast',\n",
              "     'latitude': 18.38923,\n",
              "     'longitude': -66.05525}]}],\n",
              " 'award': ['DE-AC02-05CH11231', 'DE-SC0012704'],\n",
              " 'funder': [{'@type': 'Organization',\n",
              "   'name': 'U.S. DOE > Office of Science > Biological and Environmental Research (BER)'}],\n",
              " 'temporalCoverage': {'startDate': '2017-03-03',\n",
              "  'endDate': '2017-03-09',\n",
              "  '@type': 'DateTime'},\n",
              " 'editor': {'@type': 'Person',\n",
              "  '@id': 'http://orcid.org/0000-0003-4136-8971',\n",
              "  'givenName': 'Shawn',\n",
              "  'familyName': 'Serbin',\n",
              "  'affiliation': 'Brookhaven National Laboratory',\n",
              "  'email': 'sserbin@bnl.gov'},\n",
              " 'provider': {'@type': 'Organization',\n",
              "  'identifier': {'@type': 'PropertyValue',\n",
              "   'propertyID': 'ess-dive',\n",
              "   'value': 'a441fe85-5ac3-41b1-bbe5-46df92682609'},\n",
              "  'name': 'Next-Generation Ecosystem Experiments (NGEE) Tropics',\n",
              "  'member': {'@type': 'Person',\n",
              "   'givenName': 'Jeffrey',\n",
              "   'familyName': 'Chambers',\n",
              "   'jobTitle': 'Principal Investigator',\n",
              "   'affiliation': 'Lawrence Berkeley National Laboratory',\n",
              "   'email': 'jchambers@lbl.gov'}},\n",
              " 'measurementTechnique': ['Sample details were recorded at the time of field sampling. Leaf samples were photographed with unique SampleID label. Species were identified either using existing, previously identified trees or by later conducting species identification based on sample vouchers. Sample records were cross checked against other related datasets (NGT0078, 79) for consistency of species, sample data and site.'],\n",
              " 'distribution': [{'contentSize': 1.9296875,\n",
              "   'contentUrl': 'https://data.ess-dive.lbl.gov/catalog/d1/mn/v2/object/ess-dive-1e92402c98110a3-20240913T175522805088',\n",
              "   'encodingFormat': 'text/csv',\n",
              "   'identifier': 'ess-dive-1e92402c98110a3-20240913T175522805088',\n",
              "   'name': 'NGT0077_locations.csv'},\n",
              "  {'contentSize': 9.6533203125,\n",
              "   'contentUrl': 'https://data.ess-dive.lbl.gov/catalog/d1/mn/v2/object/ess-dive-bf58a2ab1d40f9f-20241028T151709835342',\n",
              "   'encodingFormat': 'https://eml.ecoinformatics.org/eml-2.2.0',\n",
              "   'identifier': 'ess-dive-bf58a2ab1d40f9f-20241028T151709835342',\n",
              "   'name': 'G_LiHT_Campaign_Leaf_Sample_details_photos_March_2017_Puerto_Rico.xml'},\n",
              "  {'contentSize': 1592864.58203125,\n",
              "   'contentUrl': 'https://data.ess-dive.lbl.gov/catalog/d1/mn/v2/object/ess-dive-a421d695ce279f7-20220608T192417400244',\n",
              "   'encodingFormat': 'application/zip',\n",
              "   'identifier': 'ess-dive-a421d695ce279f7-20220608T192417400244',\n",
              "   'name': 'NGT0077_PR2017samples_20200923222634_20200923222634.zip'}],\n",
              " 'flmd_url': {},\n",
              " 'csv_files': {'NGT0077_locations.csv': 'https://data.ess-dive.lbl.gov/catalog/d1/mn/v2/object/ess-dive-1e92402c98110a3-20240913T175522805088'}}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "no_flmd_datasets[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "d12a4756-3b84-473c-b346-2640c5630235",
      "metadata": {
        "id": "d12a4756-3b84-473c-b346-2640c5630235"
      },
      "outputs": [],
      "source": [
        "# Select the dataset you want to look at and decide which files you want to print out\n",
        "ds_idx_no_flmd = 3\n",
        "file_type = 'all'  # 'all' or 'csv' or 'pdf' or 'zip'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0207e8ce-4e09-481c-a673-7df51eb74422",
      "metadata": {
        "id": "0207e8ce-4e09-481c-a673-7df51eb74422"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "a9872076",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9872076",
        "outputId": "aa0a631c-b5d2-4412-8081-04f54a33050d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G-LiHT Campaign Leaf Sample details & photos, March 2017: Puerto Rico\n",
            "========================================\n",
            "Index 0: NGT0077_locations.csv\n",
            "  encoding: text/csv\n",
            "  url: https://data.ess-dive.lbl.gov/catalog/d1/mn/v2/object/ess-dive-1e92402c98110a3-20240913T175522805088\n",
            "Index 1: G_LiHT_Campaign_Leaf_Sample_details_photos_March_2017_Puerto_Rico.xml\n",
            "  encoding: https://eml.ecoinformatics.org/eml-2.2.0\n",
            "  url: https://data.ess-dive.lbl.gov/catalog/d1/mn/v2/object/ess-dive-bf58a2ab1d40f9f-20241028T151709835342\n",
            "Index 2: NGT0077_PR2017samples_20200923222634_20200923222634.zip\n",
            "  encoding: application/zip\n",
            "  url: https://data.ess-dive.lbl.gov/catalog/d1/mn/v2/object/ess-dive-a421d695ce279f7-20220608T192417400244\n"
          ]
        }
      ],
      "source": [
        "# use this helper function to print the names of the files in the dataset you chose\n",
        "inspect_dataset_distribution(no_flmd_datasets[ds_idx_no_flmd], file_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "763e43e1-f7e9-43b4-9f49-f27f029dc50e",
      "metadata": {
        "id": "763e43e1-f7e9-43b4-9f49-f27f029dc50e"
      },
      "source": [
        "### 10. Select zip file to inspect"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "718c1a6d-4638-4c38-9c9b-ab697db6555a",
      "metadata": {
        "id": "718c1a6d-4638-4c38-9c9b-ab697db6555a"
      },
      "source": [
        "<strong><span style=\"color:blue\">Enter INPUT</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "37afd2ab-7f98-45ce-9bc7-1284fc48db7a",
      "metadata": {
        "id": "37afd2ab-7f98-45ce-9bc7-1284fc48db7a"
      },
      "outputs": [],
      "source": [
        "# Grab the specific dataset details from the dataset we chose from the list of datasets we selected originally:\n",
        "dataset_detail = dataset_details[2]\n",
        "\n",
        "# Index of zip file from file distribution\n",
        "zip_file_index = 3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "775be58b-024d-4d62-bb6f-4e0bb010d954",
      "metadata": {
        "id": "775be58b-024d-4d62-bb6f-4e0bb010d954"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "fb26ebfa-6c4f-4bbc-afc4-2e6f6da63545",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb26ebfa-6c4f-4bbc-afc4-2e6f6da63545",
        "outputId": "b3dadee9-ce8b-4b08-cbd1-cc2918133633"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success!\n",
            "PR2017_LMA_20190218212240.zip contents:\n",
            "=================================\n",
            "Index 0: NGEE-Tropics_Puerto_Rico_March2017_LMA.xlsx\n",
            "Index 1: __MACOSX/\n",
            "Index 2: __MACOSX/._NGEE-Tropics_Puerto_Rico_March2017_LMA.xlsx\n",
            "Index 3: File_Submission_Metadata_2017_PR_LMA.xlsx\n",
            "Index 4: __MACOSX/._File_Submission_Metadata_2017_PR_LMA.xlsx\n",
            "Index 5: NGEE-Tropics_Puerto_Rico_March2017_Leaf_Sample_Detail.xlsx\n",
            "Index 6: __MACOSX/._NGEE-Tropics_Puerto_Rico_March2017_Leaf_Sample_Detail.xlsx\n",
            "Index 7: E-Field_Log_2017_BNL_PuertoRico.xlsx\n",
            "Index 8: __MACOSX/._E-Field_Log_2017_BNL_PuertoRico.xlsx\n"
          ]
        }
      ],
      "source": [
        "# use this helper function to list the files in the zip file\n",
        "fn, zip_download = inspect_zip_file_contents(dataset_detail, zip_file_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f85d097d-d43d-48b2-86ca-74d6e20d2817",
      "metadata": {
        "id": "f85d097d-d43d-48b2-86ca-74d6e20d2817"
      },
      "source": [
        "### 11. Select csv file within zip file that you want to inspect"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96203c52-d1c2-441f-bc9b-ab4db42ed5bb",
      "metadata": {
        "id": "96203c52-d1c2-441f-bc9b-ab4db42ed5bb"
      },
      "source": [
        "<strong><span style=\"color:blue\">Enter INPUT</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "7a7f6ffb-06f2-4d36-a78d-9f6908eb2227",
      "metadata": {
        "id": "7a7f6ffb-06f2-4d36-a78d-9f6908eb2227"
      },
      "outputs": [],
      "source": [
        "# Select the index for the file you want to look at\n",
        "csv_file_idx = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc4e0da9-a864-4d7e-bc1d-3036c7f68291",
      "metadata": {
        "id": "dc4e0da9-a864-4d7e-bc1d-3036c7f68291"
      },
      "source": [
        "#### Before you can view the file, let's take a look at the file structure to understand how to parse it.\n",
        "For this tutorial, we know this dataset has structured CSV files and it may have multiple rows of metadata. Let's look at the first line to see where the header rows start.   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "540537cb-1c2a-4f91-8c33-64bc671f7ec5",
      "metadata": {
        "id": "540537cb-1c2a-4f91-8c33-64bc671f7ec5"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "0fc8b861-cff0-4506-a78d-522a0f82bd4a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fc8b861-cff0-4506-a78d-522a0f82bd4a",
        "outputId": "1672053d-8ded-4819-985a-40daebe98eb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PK\u0003\u0004\u0014\u0000\u0006\u0000\b\u0000\u0000\u0000!\u0000|l\u0016i\u0001\u0000\u0000\u0005\u0000\u0000\u0013\u0000\b\u0002[Content_Types].xml \u0004\u0002(\u0000\u0002\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000j0\u0014\u0007{D\u001d1^&=@`w\u001au)4_Oo8^5&[B@l2S\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print out the first line of the file and extract header row number\n",
        "# ===================================\n",
        "csv_file_name = zip_download.namelist()[csv_file_idx]\n",
        "\n",
        "header_row = 0\n",
        "with zip_download.open(csv_file_name) as f:\n",
        "    line = f.readline().decode('latin-1')  # Decode the bytes to string\n",
        "    print(line)\n",
        "    if \"# HeaderRows_\" in line:\n",
        "        header_row = int(line.split(\"# HeaderRows_\")[1])  # Extract the number part\n",
        "        print(f\"Extracted header row number: {header_row}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e4e7048-2118-4f00-aaec-e602c432299f",
      "metadata": {
        "id": "8e4e7048-2118-4f00-aaec-e602c432299f"
      },
      "source": [
        "#### This CSV happens to follow the CSV Guidelines and we can easily print out the number of header rows. To verify that this is true, we'll print this number of rows first."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8aa64c95-789f-4e92-b054-19f0c5963d14",
      "metadata": {
        "id": "8aa64c95-789f-4e92-b054-19f0c5963d14"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "929d2604-c404-41dd-8abd-08879a46a3f5",
      "metadata": {
        "id": "929d2604-c404-41dd-8abd-08879a46a3f5"
      },
      "outputs": [],
      "source": [
        "# Print out rows up to header row number\n",
        "if header_row > 0:\n",
        "    with zip_download.open(csv_file_name) as f:\n",
        "        for i in range(header_row):\n",
        "            print(f.readline())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb4ac871-f446-4e06-a891-2ed898bbf6b4",
      "metadata": {
        "id": "bb4ac871-f446-4e06-a891-2ed898bbf6b4"
      },
      "source": [
        "#### Look at the last line that is printed - that should be the column names!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2d5700c-5689-4bd6-ba7c-bcf6a956ae8f",
      "metadata": {
        "id": "a2d5700c-5689-4bd6-ba7c-bcf6a956ae8f"
      },
      "source": [
        "#### So to correctly put a csv file into a pandas dataframe, you want to take that header row number (7 in this example) and subtract 1, to keep the row with the data column names. In this example we want to skip 6 rows.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d98ec3c3-93af-47f5-aef5-769842f8c2a0",
      "metadata": {
        "id": "d98ec3c3-93af-47f5-aef5-769842f8c2a0"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "54fd03d5-eaa2-47e7-b75f-794177e602cc",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "id": "54fd03d5-eaa2-47e7-b75f-794177e602cc",
        "outputId": "bdc36ea2-cc2b-470a-a88e-0f1d0a7327ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The header row is row 1, so we will skip 0 rows of the file\n",
            "Attempting to read: NGEE-Tropics_Puerto_Rico_March2017_Leaf_Sample_Detail.xlsx from zip file PR2017_LMA_20190218212240.zip\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnicodeDecodeError",
          "evalue": "'utf-8' codec can't decode byte 0x98 in position 16: invalid start byte",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-b15b428f8185>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Attempting to read: {csv_file_name} from zip file {fn}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmetadata_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_download\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrows_to_skip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mzip_download_1_datasetapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip_download\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfn_datasetapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1897\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1898\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1899\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;31m# Fail here loudly instead of in cython after reading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pyarrow\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x98 in position 16: invalid start byte"
          ]
        }
      ],
      "source": [
        "rows_to_skip = header_row - 1\n",
        "print(f'The header row is row {header_row}, so we will skip {rows_to_skip} rows of the file')\n",
        "\n",
        "print(f'Attempting to read: {csv_file_name} from zip file {fn}')\n",
        "\n",
        "metadata_df = pd.read_csv(zip_download.open(csv_file_name), skiprows=rows_to_skip)\n",
        "zip_download_1_datasetapi = zip_download\n",
        "fn_datasetapi = fn\n",
        "csv_file_name_datasetapi = csv_file_name\n",
        "\n",
        "if metadata_df is not None:\n",
        "    is_csv_zipped = True\n",
        "    headers = list(metadata_df.columns)\n",
        "    data_df_datasetapi = metadata_df\n",
        "    display(metadata_df)\n",
        "else:\n",
        "    print('ERROR: Sample metadata file was not successfully loaded.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b3d3f24-b1ba-4d20-b123-ddd847f860ff",
      "metadata": {
        "id": "7b3d3f24-b1ba-4d20-b123-ddd847f860ff"
      },
      "source": [
        "### This allows you to view the datasets that we looked through manually\n",
        "### Now - let's use analyze!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "977689cf",
      "metadata": {
        "id": "977689cf"
      },
      "source": [
        "---\n",
        "# Part 3: Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68b4b063-ee9a-4e7c-b396-8ce70d634f5a",
      "metadata": {
        "id": "68b4b063-ee9a-4e7c-b396-8ce70d634f5a"
      },
      "source": [
        "## A. Begin Simple Analysis\n",
        "Now that we have identified files of interest, let's start using them and begin our investigation!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4e0b7f9-3092-4a5d-9b1f-a6053f19088d",
      "metadata": {
        "id": "e4e0b7f9-3092-4a5d-9b1f-a6053f19088d"
      },
      "source": [
        "### 1. Load the two selected csv data files into pandas dataframes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dee1a06a-6ec2-43bf-a7d1-71810ad25d0f",
      "metadata": {
        "id": "dee1a06a-6ec2-43bf-a7d1-71810ad25d0f"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3b03a95-93ca-495d-985f-e7684c4799ad",
      "metadata": {
        "scrolled": true,
        "id": "b3b03a95-93ca-495d-985f-e7684c4799ad"
      },
      "outputs": [],
      "source": [
        "# Data identified from Basic Search\n",
        "# ===================================\n",
        "# grab and print identifying information from the dataset details\n",
        "index_dataset_api_dataset = total_doi_array.index(no_flmd_datasets[ds_idx_no_flmd].get('@id'))\n",
        "print(datasets[index_dataset_api_dataset].get('dataset').get('@id'))\n",
        "print(datasets[index_dataset_api_dataset].get('dataset').get('name'))\n",
        "data_df_datasetapi_name = datasets[index_dataset_api_dataset].get('dataset').get('name')\n",
        "print(datasets[index_dataset_api_dataset].get('viewUrl'))\n",
        "\n",
        "# display the pandas dataframe containing the datafile\n",
        "display(data_df_datasetapi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdec7422-825e-4d05-a457-362182220ec6",
      "metadata": {
        "id": "fdec7422-825e-4d05-a457-362182220ec6"
      },
      "outputs": [],
      "source": [
        "# Otherwise: can load any data that you downloaded previously."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f8c3b02-727c-49de-b193-84fb72556fa2",
      "metadata": {
        "id": "5f8c3b02-727c-49de-b193-84fb72556fa2"
      },
      "source": [
        "### 2. Look at basic statistics and data coverage\n",
        "\n",
        "Print out the basic statistics of the variables, as well as the date range for both dataset files. <br>\n",
        "By gleaning more information - we can begin to determine which dataset may be useful for our science question."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdf3e25a-2b73-4e4f-a135-c551ce6838bc",
      "metadata": {
        "id": "bdf3e25a-2b73-4e4f-a135-c551ce6838bc"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d039260-b63f-44fe-ac53-44a86d94d75d",
      "metadata": {
        "id": "8d039260-b63f-44fe-ac53-44a86d94d75d"
      },
      "outputs": [],
      "source": [
        "for data_df in ['data_df_datasetapi']:\n",
        "    print(vars()[str(data_df)+'_name'])\n",
        "    date_range = (vars()[data_df]['DateTime'].min(), vars()[data_df]['DateTime'].max())\n",
        "    print(f\"Date range: {date_range[0]} to {date_range[1]}\")\n",
        "    display(vars()[data_df].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89facf27-c2da-41ee-af7e-16d33a3e022a",
      "metadata": {
        "id": "89facf27-c2da-41ee-af7e-16d33a3e022a"
      },
      "source": [
        "### 3. Plot the data to visualize basic patterns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bc734bd-010c-4802-be1f-9165af6eb4d1",
      "metadata": {
        "id": "1bc734bd-010c-4802-be1f-9165af6eb4d1"
      },
      "source": [
        "<strong><span style=\"color:blue\">Enter INPUT</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5104e5b9-66c1-423e-be74-7172b263e88a",
      "metadata": {
        "id": "5104e5b9-66c1-423e-be74-7172b263e88a"
      },
      "outputs": [],
      "source": [
        "## DATASET API RESULT\n",
        "\n",
        "# Select the dataset you want to plot\n",
        "dataframe = data_df_datasetapi\n",
        "\n",
        "# Select the variables that you are interest in plotting\n",
        "variables_of_interest = ['Temperature','Specific_Conductance']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d75a170-5211-43b5-a3ee-496adc6953b0",
      "metadata": {
        "id": "1d75a170-5211-43b5-a3ee-496adc6953b0"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e537ae89-ed88-4f77-9002-da1d4992423d",
      "metadata": {
        "id": "e537ae89-ed88-4f77-9002-da1d4992423d"
      },
      "outputs": [],
      "source": [
        "# Plot the data\n",
        "# ===================================\n",
        "# Convert 'DateTime'to datetime using:\n",
        "dataframe['DateTime'] = pd.to_datetime(dataframe['DateTime'])\n",
        "\n",
        "num_plots = len(variables_of_interest)\n",
        "\n",
        "# Create a figure with two subplots\n",
        "fig, axs = plt.subplots(num_plots, 1, figsize=(10, 8))\n",
        "\n",
        "for i, ax in enumerate(axs):\n",
        "    # Plot VARIABLE over time\n",
        "    ax.plot(dataframe['DateTime'], dataframe[variables_of_interest[i]], label=variables_of_interest[i])\n",
        "    ax.set_title(variables_of_interest[i] + ' over Time')\n",
        "    ax.set_xlabel('DateTime')\n",
        "    ax.set_ylabel(variables_of_interest[i])\n",
        "    ax.grid(True)\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "052c2595-ec88-4aaa-adf3-ffd405ef9a36",
      "metadata": {
        "id": "052c2595-ec88-4aaa-adf3-ffd405ef9a36"
      },
      "source": [
        "### Using this plot, we can visually see the data coverage, and start to think about patterns in the data.\n",
        "### Visualizing the data can help you determine if this data file may work for your science question. You can keep going with analysis by inserting your custom analysis code here! Or, you can move on to the next section and download the data for future use.\n",
        "RESOURCE: [Python pandas user guide](https://pandas.pydata.org/docs/user_guide/index.html#user-guide)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c90f5fab",
      "metadata": {
        "id": "c90f5fab"
      },
      "source": [
        "---\n",
        "# Part 4: Download Files and Save the Download Log\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d6e8c2b",
      "metadata": {
        "id": "5d6e8c2b"
      },
      "source": [
        "## A. Download file(s) to local directory\n",
        "If desired, change save location and file location.\n",
        "Otherwise the path configured at the begining of the notebook will be used."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c71224e3",
      "metadata": {
        "id": "c71224e3"
      },
      "source": [
        "### 1. Ensure you have the right file to download."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc270dc6-d076-41d9-b63d-be385bfd914d",
      "metadata": {
        "id": "cc270dc6-d076-41d9-b63d-be385bfd914d"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a63aa778-9a99-4fcc-91b5-b13f5170bd2a",
      "metadata": {
        "scrolled": true,
        "id": "a63aa778-9a99-4fcc-91b5-b13f5170bd2a"
      },
      "outputs": [],
      "source": [
        "# Run cell to view dataset to check if this is the one you want to download\n",
        "datafile_to_download = \"data_df_datasetapi\" # \"data_df_deep_dive\" >> this is if you use the file exploration in Part 5!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7f29daf",
      "metadata": {
        "id": "d7f29daf"
      },
      "source": [
        "### 2. Download the file and update the file download log.\n",
        "#### This example will download the whole zip file"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bc0884c-8236-43f3-83c6-919cb23923eb",
      "metadata": {
        "id": "4bc0884c-8236-43f3-83c6-919cb23923eb"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b7b684c-5390-4727-bddf-fb0a9b9e62bf",
      "metadata": {
        "id": "0b7b684c-5390-4727-bddf-fb0a9b9e62bf"
      },
      "outputs": [],
      "source": [
        "# Download the zip file to the chosen directory\n",
        "if datafile_to_download == \"data_df_datasetapi\":\n",
        "    file_indices = [zip_file_index]\n",
        "    dataset_details_chosen =  no_flmd_datasets[ds_idx_no_flmd]\n",
        "    dataset_citation = citations_list.get(dataset_details_chosen.get('@id'))\n",
        "\n",
        "    ds_doi = download_selected_files(dataset_details_chosen, file_indices, download_dir_path,citation=dataset_citation)\n",
        "\n",
        "# if datafile_to_download == \"data_df_deep_dive\":\n",
        "#     dataset_details_chosen =  dataset_details[total_doi_array.index(current_response_json.get('doi'))]\n",
        "\n",
        "#     files_deep_dive = dataset_details[total_doi_array.index(current_response_json.get('doi'))].get('distribution')\n",
        "#     zipfile_to_download = current_response_json.get('data_file').split('/', 1)[0]\n",
        "#     index = next((i for i, item in enumerate(files_deep_dive) if item['name'] == zipfile_to_download), None)\n",
        "#     file_indices = [index]\n",
        "\n",
        "#     file_to_download = current_response_json.get('data_file').rsplit('/', 1)[-1]\n",
        "\n",
        "#     dataset_citation = citations_list.get(current_response_json.get('doi'))\n",
        "\n",
        "#     ds_doi = download_selected_files(dataset_details_chosen, file_indices, download_dir_path, citation=dataset_citation)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1523962",
      "metadata": {
        "id": "b1523962"
      },
      "source": [
        "#### You can view the Download log file to see a list of the files that we downloaded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "172064b3",
      "metadata": {
        "scrolled": true,
        "id": "172064b3"
      },
      "outputs": [],
      "source": [
        "# Optional: display the whole download file log\n",
        "# ===================================\n",
        "display(download_file_log)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19f69270",
      "metadata": {
        "id": "19f69270"
      },
      "source": [
        "### 3. Download the Download File Log to get a list of citations of data that we downloaded"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1268729-8615-4934-af50-06093c7c1ace",
      "metadata": {
        "id": "f1268729-8615-4934-af50-06093c7c1ace"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf15a785",
      "metadata": {
        "id": "cf15a785"
      },
      "outputs": [],
      "source": [
        "log_filename = 'essdive_downloaded_files_log.csv'\n",
        "log_fn_path = download_dir_path / log_filename\n",
        "\n",
        "with open(log_fn_path, mode='w') as f:\n",
        "    csv_writer = csv.writer(f)\n",
        "    csv_writer.writerow(['dataset_id', 'file_name', 'access_datetime', 'access_url', 'dataset_name', 'citation'])\n",
        "\n",
        "    for ds_id, log_info in download_file_log.items():\n",
        "        ds_name = log_info.get('name')\n",
        "        ds_citation = log_info.get('citation')\n",
        "\n",
        "        accessed_file_list = log_info.get('downloaded_files')\n",
        "        for accessed_file in accessed_file_list:\n",
        "            fn, fn_url, access_ts = accessed_file\n",
        "\n",
        "            csv_writer.writerow([ds_id, fn, access_ts, fn_url, ds_name, ds_citation])\n",
        "\n",
        "print(f'Check {str(download_dir_path)} for the log file: {log_filename}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "903e9b0a",
      "metadata": {
        "id": "903e9b0a"
      },
      "source": [
        "# That's a wrap!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca803ce3",
      "metadata": {
        "id": "ca803ce3"
      },
      "source": [
        "-----\n",
        "<br>\n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1dcecbd-2ce5-4898-9996-f7a781d555fa",
      "metadata": {
        "id": "f1dcecbd-2ce5-4898-9996-f7a781d555fa"
      },
      "source": [
        "# Part 5. Workflow Using Deep Dive API"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ae2a3f5-a69a-44d7-95c1-6f7fd12a3b29",
      "metadata": {
        "id": "5ae2a3f5-a69a-44d7-95c1-6f7fd12a3b29"
      },
      "source": [
        "## A. Searching for Data using Deep Dive API with the Fusion Database\n",
        "### (Alternative to Part 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d8aa6c2-15e2-429e-ac4e-0177470b04ef",
      "metadata": {
        "id": "7d8aa6c2-15e2-429e-ac4e-0177470b04ef"
      },
      "source": [
        "The Fusion Database allows you to search within files and across datasets that follow structured data. Sometimes, datasets don't include all of the information in the metadata and thus may not come up in just the Dataset API search. You can search across all datasets available in the Fusion DB for specific field names.\n",
        "\n",
        "**See additional details for Deep Dive search in API techincal documentation:** https://fusion.ess-dive.lbl.gov/#/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7792c4c-f0a1-4018-8caa-b2cad7528ebf",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "f7792c4c-f0a1-4018-8caa-b2cad7528ebf"
      },
      "source": [
        "### Search within datasets for certain measured data\n",
        "The Fusion Database only searches structured data, meaning that the total list of potential datasets is limited. However, if you find datasets of interest, you will be able to explore inside them much more deeply. <br>\n",
        "You can search for datasets using any of the following parameters:\n",
        "- **rowStart** (integer, query): The row number to start on. Use this for paging results, minimum: 1\n",
        "- **pageSize** (integer, query): The number of datasets to return, maximum: 100\n",
        "- **doi** (string array, query): The digital object identifier (doi) representing a dataset\n",
        "- **fieldName** (string, query): The field name to search for, minLength: 1, maxLength: 100\n",
        "- **fieldDefinition** (string, query): Search the field definition, minLength: 1, maxLength: 100\n",
        "- **recordCountMin** (integer, query): Filter by record count greater that or equal to.\n",
        "- **recordCountMax** (integer, query): Filter by record count less than or equal to.\n",
        "- **fieldValueText** (string, query): Filter by a text field value. Search is case insensitive\n",
        "- **fieldValueNumeric** (integer, query): Filter by a numeric value that is between min and max summary values.\n",
        "- **fieldValueDate** (string($date), query): Filter by a date/datetime value that is between min and max summary values. Date format: (yyyy-mm-dd), Datetime format: (yyyy-mm-ddTHH:MM:SS)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e99871d8-96b4-498d-9c22-555f27c2e09f",
      "metadata": {
        "id": "e99871d8-96b4-498d-9c22-555f27c2e09f"
      },
      "source": [
        "### General Search\n",
        "You can search within individual DOIs, multiple DOIs, or across all available datasets that are available in the Fusion Database. Here, we will do a search without specifying the specific DOI, to explore if there are other datasets of interest. In the next section, we will do searches on a couple of DOIs to see if they have specific files we are interested in."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e431a30",
      "metadata": {
        "id": "8e431a30"
      },
      "source": [
        "### 1. Enter Search Parameters and make API call\n",
        "<strong><span style=\"color:blue\">Enter INPUT</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46126330",
      "metadata": {
        "id": "46126330"
      },
      "outputs": [],
      "source": [
        "# Enter search terms\n",
        "# For an exact match, put the string in quotes, e.g. \"\\\"Leaf\"\\\" is an exact match, \"Leaf\" is any match\n",
        "fieldName=\"conductance\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13b36e83",
      "metadata": {
        "id": "13b36e83"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20f372ea-a3d4-47c0-9b81-8c532f5f02f2",
      "metadata": {
        "id": "20f372ea-a3d4-47c0-9b81-8c532f5f02f2"
      },
      "outputs": [],
      "source": [
        "# Contruct URL query to send to the Deep Dive API\n",
        "get_deepdive_response = f\"{essdive_deepdive_url}/api/v1/deepdive?rowStart=1&pageSize=100&fieldName={fieldName}\"\n",
        "\n",
        "# Send request to API\n",
        "response_deepdive = requests.get(get_deepdive_response)\n",
        "\n",
        "# Review the response and debug if needed\n",
        "if response_deepdive.status_code == 200:\n",
        "    # Success\n",
        "    response_json_deepdive = response_deepdive.json()\n",
        "    results_deepdive = response_deepdive.json()['results']\n",
        "    print(\"Success! Continue to look at the search results\")\n",
        "else:\n",
        "    # There was an error\n",
        "    print(\"There was an error. Stop here and debug the issue. Email ess-dive-support@lbl.gov if you need assistance. \\n\")\n",
        "    print(response_deepdive.text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d58dafe-878a-4890-9b39-688c7aac533b",
      "metadata": {
        "scrolled": true,
        "id": "7d58dafe-878a-4890-9b39-688c7aac533b"
      },
      "outputs": [],
      "source": [
        "# OPTIONAL: View the JSON response\n",
        "# ===================================\n",
        "display(response_json_deepdive)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e027645f-8e74-425d-a28e-95f6629d7b4d",
      "metadata": {
        "id": "e027645f-8e74-425d-a28e-95f6629d7b4d"
      },
      "source": [
        "### 2. Inspect the search results - as a Pandas Dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74a249e8-f847-40b5-86d7-804cf84b0d55",
      "metadata": {
        "id": "74a249e8-f847-40b5-86d7-804cf84b0d55"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e63c45a-2bbc-4fe9-91ba-1dc842763e07",
      "metadata": {
        "scrolled": true,
        "id": "0e63c45a-2bbc-4fe9-91ba-1dc842763e07"
      },
      "outputs": [],
      "source": [
        "# Create and display a pandas dataframe for the report\n",
        "project_report_deepdive =grab_metadata(results_deepdive)\n",
        "display(project_report_deepdive.style.set_properties(**{'text-align': 'left'}))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd2db726",
      "metadata": {
        "id": "cd2db726"
      },
      "source": [
        "### This example for \"conductance\" headers returns 98 files that match this search. How do we narrow the search down further?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "494fa9b6-bf40-4fd7-a4d4-3135669b5800",
      "metadata": {
        "id": "494fa9b6-bf40-4fd7-a4d4-3135669b5800"
      },
      "source": [
        "---\n",
        "## B. Exploring Data using Deep Dive\n",
        "### (Alternative to Part 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "007c650b-5a0d-48ee-9724-12635ff0ce40",
      "metadata": {
        "id": "007c650b-5a0d-48ee-9724-12635ff0ce40"
      },
      "source": [
        "_Inspect datasets with structured data (FLMD)_ <br>\n",
        "This section picks up where the **[Part 1: Searching for Data](#-Part-1-Searching-on-ESS-DIVE)** leaves off - list of identified datasets in variable name _datasets_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35478109-e4ef-4dfa-bfaa-b864ce2f3163",
      "metadata": {
        "id": "35478109-e4ef-4dfa-bfaa-b864ce2f3163"
      },
      "source": [
        "### 1. Use the Deep Dive API (Query-Data) to look in specific datasets\n",
        "Using the datasets that **do** have FLMD, we will explore inside these files to find ones we are interested in for analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1a5152d-e52a-4fa7-964e-7854dd06fd6e",
      "metadata": {
        "id": "d1a5152d-e52a-4fa7-964e-7854dd06fd6e"
      },
      "source": [
        "In Part 1 we used the Deep Dive (Query-Data) to look for files with certain terms across pany public dataset that is in the Fusion DB.\n",
        "\n",
        "Now, we will specify which datasets we want to look at to see (a) if they are available on Deep Dive and (b) what specific files may be of interest. We will need their DOIs to do so."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c21f0da-19cc-470e-a39e-1651d9741901",
      "metadata": {
        "id": "8c21f0da-19cc-470e-a39e-1651d9741901"
      },
      "source": [
        "***The DOIs that we will use in this example come from our Dataset API search results (Part 1, Section A, Step 3: Subset Search Results).***"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "331aeb5e-6d99-4788-8c2e-4f999714c909",
      "metadata": {
        "id": "331aeb5e-6d99-4788-8c2e-4f999714c909"
      },
      "source": [
        "<strong><span style=\"color:blue\">Enter INPUT</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75295542-9157-4be4-b6a9-47f72ebbd4a0",
      "metadata": {
        "id": "75295542-9157-4be4-b6a9-47f72ebbd4a0"
      },
      "outputs": [],
      "source": [
        "# Enter search terms\n",
        "fieldName=\"conductance\"\n",
        "\n",
        "# Select the datasets that you would like to check.\n",
        "# Change the indices in the bracket for the indices of the datasets from the cell above\n",
        "doi_array = total_doi_array[0:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "824e3392-e8c7-47d3-8e91-cf5bb93519e1",
      "metadata": {
        "id": "824e3392-e8c7-47d3-8e91-cf5bb93519e1"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3412bf4-352f-4ce9-bb56-97eb14f1bf6b",
      "metadata": {
        "id": "b3412bf4-352f-4ce9-bb56-97eb14f1bf6b"
      },
      "outputs": [],
      "source": [
        "# Contruct URL query to send to the Deep Dive API\n",
        "doi_information=\"\"\n",
        "for d in doi_array:\n",
        "    doi_information=doi_information + \"&doi=\"+d\n",
        "\n",
        "get_deepdive_response = f\"{essdive_deepdive_url}/api/v1/deepdive?rowStart=1&pageSize=100&fieldName={fieldName}{doi_information}\"\n",
        "\n",
        "# Send request to API\n",
        "response_deep_dive = requests.get(get_deepdive_response)\n",
        "\n",
        "# Review the response and debug if needed\n",
        "if response_deep_dive.status_code == 200:\n",
        "    # Success\n",
        "    response_json_deep_dive = response_deep_dive.json()\n",
        "    results_deep_dive = response_deep_dive.json()['results']\n",
        "    print(\"Success! Continue to look at the search results\")\n",
        "else:\n",
        "    # There was an error\n",
        "    print(\"There was an error. Stop here and debug the issue. Email ess-dive-support@lbl.gov if you need assistance. \\n\")\n",
        "    print(response_deep_dive.text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "243817ba-dcac-4438-b1e4-a5246ca38135",
      "metadata": {
        "id": "243817ba-dcac-4438-b1e4-a5246ca38135"
      },
      "source": [
        "### 2. View the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8f1e67a-791e-47ea-96d2-fd9f66c9ddf0",
      "metadata": {
        "scrolled": true,
        "id": "a8f1e67a-791e-47ea-96d2-fd9f66c9ddf0"
      },
      "outputs": [],
      "source": [
        "# OPTIONAL: View the JSON response\n",
        "# ===================================\n",
        "display(response_json_deep_dive)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "514ab288",
      "metadata": {
        "id": "514ab288"
      },
      "source": [
        "### In this example, I'm interested in looking at the results with the most amount of data records. I sorted my table to show me which those are so I can easily reference the index.\n",
        "There is also the option to the view the table unsorted."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2a608b1-76f5-4844-b1ed-8735d053c62a",
      "metadata": {
        "id": "c2a608b1-76f5-4844-b1ed-8735d053c62a"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ac4fcb6-7cda-4d04-8cd6-02ac63e524a3",
      "metadata": {
        "scrolled": true,
        "id": "2ac4fcb6-7cda-4d04-8cd6-02ac63e524a3"
      },
      "outputs": [],
      "source": [
        "# Create pandas dataframe for the report\n",
        "project_report_deep_dive = grab_metadata(results_deep_dive)\n",
        "\n",
        "# This code sorts the dataframe by total records\n",
        "columns_to_sort = ['Total_records']\n",
        "ascending = [False]\n",
        "project_report_sorted_deep_dive = project_report_deep_dive.sort_values(by=columns_to_sort,ascending=ascending)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08fb278e-1ed8-4729-bcf3-6a229207a5b4",
      "metadata": {
        "id": "08fb278e-1ed8-4729-bcf3-6a229207a5b4"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9acf4a8-b487-43b2-8b37-16ede2069948",
      "metadata": {
        "scrolled": true,
        "id": "c9acf4a8-b487-43b2-8b37-16ede2069948"
      },
      "outputs": [],
      "source": [
        "## Choose the dataframe to display - Sorted or Non-Sorted\n",
        "## =================\n",
        "## Display Sorted dataframe\n",
        "display(project_report_sorted_deep_dive.style.set_properties(**{'text-align': 'left'}))\n",
        "\n",
        "## Uncomment to display Non-Sorted dataframe\n",
        "#display(project_report_deep_dive.style.set_properties(**{'text-align': 'left'}))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e3b2e63-0c8d-4826-8bb1-ace02a458456",
      "metadata": {
        "id": "7e3b2e63-0c8d-4826-8bb1-ace02a458456"
      },
      "source": [
        "### Let's grab the file(s) that we are interested in"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a298d04",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "9a298d04"
      },
      "source": [
        "### 3. Use Get-Dataset-File to identify specific files\n",
        "Aside from identifying specific files in datasets, the Deep Dive API can also retrieves a dataset file by its file path, using a different request message (called an end point). <br>\n",
        "Learn more at Fusion docs: [Get-Dataset-File](https://fusion.ess-dive.lbl.gov/#/default/get_dataset_file_api_v1_deepdive__doi___file_path__get)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fde6bd0-0da7-4c1b-b42d-efcfcd700459",
      "metadata": {
        "id": "0fde6bd0-0da7-4c1b-b42d-efcfcd700459"
      },
      "source": [
        "### From the previous list of files, we will use the index to then grab the DOI and file name to query the Deep Dive API.\n",
        "<strong><span style=\"color:blue\">Enter INPUT</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db86eab1-cc97-46b4-a964-298f84f6d76f",
      "metadata": {
        "id": "db86eab1-cc97-46b4-a964-298f84f6d76f"
      },
      "outputs": [],
      "source": [
        "# Select an index from the pandas dataframe to choose a file to investigate\n",
        "i_of_interest= 69"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7e45c0c-cab4-4d53-9fd9-bf92e6b18b03",
      "metadata": {
        "id": "f7e45c0c-cab4-4d53-9fd9-bf92e6b18b03"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cf07123-6839-48c8-8ab6-7ebf9d543c0a",
      "metadata": {
        "id": "1cf07123-6839-48c8-8ab6-7ebf9d543c0a"
      },
      "outputs": [],
      "source": [
        "# The format for the URL Deep Dive call is - DOI:file_name\n",
        "doi_file_information = project_report_sorted_deep_dive.loc[i_of_interest]['DOI'] + ':' + project_report_sorted_deep_dive.loc[i_of_interest]['File']\n",
        "# using the DOI, grab the index from the flmd_datasets\n",
        "index_for_datasets = doi_array.index(project_report_sorted_deep_dive.loc[i_of_interest]['DOI'])\n",
        "\n",
        "# Contruct URL query to send to the Deep Dive API\n",
        "get_deepdive_response_file = f\"{essdive_deepdive_url}/api/v1/deepdive/{doi_file_information}\"\n",
        "\n",
        "# Send request to API\n",
        "response_deepdive_file = requests.get(get_deepdive_response_file)\n",
        "\n",
        "# Review the response and debug if needed\n",
        "if response_deepdive_file.status_code == 200:\n",
        "    # Success\n",
        "    response_deepdive_file_json = response_deepdive_file.json()\n",
        "    print(f\"Success for file {doi_file_information}! Continue to look at the search results\")\n",
        "else:\n",
        "    # There was an error\n",
        "    print(\"There was an error. Stop here and debug the issue. Email ess-dive-support@lbl.gov if you need assistance. \\n\")\n",
        "    print(response_deepdive_file.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cdbe9ee-b111-4b99-9780-324a4adddb91",
      "metadata": {
        "scrolled": true,
        "id": "7cdbe9ee-b111-4b99-9780-324a4adddb91"
      },
      "outputs": [],
      "source": [
        "# Optional: display entire json response\n",
        "# ===================================\n",
        "display(response_deepdive_file_json)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aafd92b7",
      "metadata": {
        "id": "aafd92b7"
      },
      "source": [
        "### Great! Now we have identified the file we want through the Deep Dive API. Next, we'll to look into the file itself, to see if we want to download the file."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bc62c60-026f-4f6e-b802-6d5c1d189eed",
      "metadata": {
        "id": "7bc62c60-026f-4f6e-b802-6d5c1d189eed"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "341bbd41-ebc5-4d29-a7e8-c9f69ab1c2f2",
      "metadata": {
        "id": "341bbd41-ebc5-4d29-a7e8-c9f69ab1c2f2"
      },
      "outputs": [],
      "source": [
        "# We using the file information to grab it and then visualize it\n",
        "current_response_json = response_deepdive_file_json\n",
        "\n",
        "fn_url = current_response_json['data_download']['contentUrl']\n",
        "\n",
        "try:\n",
        "# Create a request with headers\n",
        "    req = Request(fn_url)\n",
        "    req.add_header('User-Agent', 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:77.0) Gecko/20100101 Firefox/77.0')\n",
        "# Open the URL with the added headers\n",
        "    resp = urlopen(req)\n",
        "    zip_download = ZipFile(io.BytesIO(resp.read()))\n",
        "    print('Success!')\n",
        "except urllib.error.HTTPError as e:\n",
        "    print(f'HTTPError: {e.code} - {e.reason}')\n",
        "# try:\n",
        "#     request = urllib.request.Request(fn_url, headers=headers)\n",
        "\n",
        "#     with urllib.request.urlopen(request) as response:\n",
        "#         with open(file_path, 'wb') as out_file:\n",
        "#             out_file.write(response.read())\n",
        "\n",
        "# except urllib.error.HTTPError as e:\n",
        "#     print(f'HTTPError: {e.code} - {e.reason}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcb63701",
      "metadata": {
        "id": "dcb63701"
      },
      "source": [
        "#### We want to visualize this file in a pandas dataframe - thus we need to identify what the header row is.\n",
        "Let's find out by printing the first couple of lines of the file. The first line should contain a string like ` b'# HeaderRows_10\\n' `, and the number is the line of the file where the header row is.  <br>\n",
        "We will try this to identify the line where the header row is in the file."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e32531f-730e-4a44-b910-913dd35eadc8",
      "metadata": {
        "id": "6e32531f-730e-4a44-b910-913dd35eadc8"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be84f970-fb50-42f7-9472-c7d1fa8dbeda",
      "metadata": {
        "id": "be84f970-fb50-42f7-9472-c7d1fa8dbeda"
      },
      "outputs": [],
      "source": [
        "# Print out the first 2 lines of the file and extract header row number\n",
        "# ===================================\n",
        "csv_file_name_deep_dive = current_response_json['data_file']\n",
        "csv_file_name_deep_dive = csv_file_name_deep_dive.split('.zip/', 1)[1]\n",
        "header_row = 0\n",
        "with zip_download.open(csv_file_name_deep_dive) as f:\n",
        "    line = f.readline().decode('utf-8')  # Decode the bytes to string\n",
        "    print(line)\n",
        "    if \"# HeaderRows_\" in line:\n",
        "        header_row = int(line.split(\"# HeaderRows_\")[1])  # Extract the number part\n",
        "        print(f\"Extracted header row number: {header_row}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85b1044c",
      "metadata": {
        "id": "85b1044c"
      },
      "source": [
        "#### You can then verify this by printing this number of lines to see if you get a row of header. Look at the last line that is printed - that should be the column names!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0df9407-5600-4e08-ae9c-44f1ad406e1d",
      "metadata": {
        "id": "a0df9407-5600-4e08-ae9c-44f1ad406e1d"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c98a1c3-367e-4675-99cd-de69a543afc8",
      "metadata": {
        "id": "8c98a1c3-367e-4675-99cd-de69a543afc8"
      },
      "outputs": [],
      "source": [
        "# Print out rows up to header row number\n",
        "if header_row > 0:\n",
        "    with zip_download.open(csv_file_name_deep_dive) as f:\n",
        "        for i in range(header_row):\n",
        "            print(f.readline())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45d4fcd8-95cc-4d6b-ba2a-457876683649",
      "metadata": {
        "id": "45d4fcd8-95cc-4d6b-ba2a-457876683649"
      },
      "source": [
        "#### So to correctly put a csv file into a pandas dataframe, you want to take that header row number (7 in this example) and subtract 1, to keep the row with the data column names. In this example we want to skip 6 rows.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad2db20b-fce0-4285-9938-23963b0d7399",
      "metadata": {
        "id": "ad2db20b-fce0-4285-9938-23963b0d7399"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e36dffec-851a-469d-b9db-dfca831ed293",
      "metadata": {
        "scrolled": true,
        "id": "e36dffec-851a-469d-b9db-dfca831ed293"
      },
      "outputs": [],
      "source": [
        "rows_to_skip = header_row - 1\n",
        "print(f'The header row is row {header_row}, so we will skip {rows_to_skip} rows of the file')\n",
        "\n",
        "fn = current_response_json['data_download']['name']\n",
        "print(f'Attempting to read: {csv_file_name_deep_dive} from zip file {fn}')\n",
        "\n",
        "metadata_df = read_zipped_csv(zip_download, csv_file_name_deep_dive, rows_to_skip)\n",
        "zip_download_2_deep_dive = zip_download\n",
        "fn_deep_dive = fn\n",
        "\n",
        "if metadata_df is not None:\n",
        "    is_csv_zipped = True\n",
        "    headers = list(metadata_df.columns)\n",
        "    data_df_deep_dive = metadata_df\n",
        "    display(metadata_df)\n",
        "else:\n",
        "    print('ERROR: Sample metadata file was not successfully loaded.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1da82c2",
      "metadata": {
        "id": "a1da82c2"
      },
      "source": [
        "### Success! We have identified a number of files that could be relevant and we have opened one file for this example. Let's move on to visualizing this example file.\n",
        "### ( Modified from  **[Part 3: Starting Analysis](#-Part-3-Starting-Analysis)** )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7b0cc11",
      "metadata": {
        "id": "d7b0cc11"
      },
      "source": [
        "### 1. Load the two selected csv data files into pandas dataframes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4b56eb9-96ea-48e3-a51f-a815c5c02a4f",
      "metadata": {
        "id": "c4b56eb9-96ea-48e3-a51f-a815c5c02a4f"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c10d590",
      "metadata": {
        "scrolled": true,
        "id": "9c10d590"
      },
      "outputs": [],
      "source": [
        "# Data identified from Part 2\n",
        "# ===================================\n",
        "# grab and print identifying information from the dataset details\n",
        "index_deep_dive_dataset = total_doi_array.index(current_response_json.get('doi'))\n",
        "print(datasets[index_deep_dive_dataset].get('dataset').get('@id'))\n",
        "print(datasets[index_deep_dive_dataset].get('dataset').get('name'))\n",
        "data_df_deep_dive_name = datasets[index_deep_dive_dataset].get('dataset').get('name')\n",
        "print(datasets[index_deep_dive_dataset].get('viewUrl'))\n",
        "\n",
        "# display the pandas dataframe containing the datafile\n",
        "display(data_df_deep_dive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c818801c-d836-4bc8-8543-a7f4c21e33a1",
      "metadata": {
        "id": "c818801c-d836-4bc8-8543-a7f4c21e33a1"
      },
      "outputs": [],
      "source": [
        "# Otherwise: can load any data that you downloaded previously."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6c23323-6c77-47cc-9b2a-d77c8941d8e2",
      "metadata": {
        "id": "d6c23323-6c77-47cc-9b2a-d77c8941d8e2"
      },
      "source": [
        "### 2. Look at basic statistics and data coverage\n",
        "\n",
        "Print out the basic statistics of the variables, as well as the date range for both dataset files. <br>\n",
        "By gleaning more information - we can begin to determine which dataset may be useful for our science question."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0949a3ff-1926-43e5-87a6-ddfb63788c8b",
      "metadata": {
        "id": "0949a3ff-1926-43e5-87a6-ddfb63788c8b"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "390ce41a-6a74-4f90-90e8-41b053f4f185",
      "metadata": {
        "id": "390ce41a-6a74-4f90-90e8-41b053f4f185"
      },
      "outputs": [],
      "source": [
        "for data_df in ['data_df_deep_dive']:\n",
        "    print(vars()[str(data_df)+'_name'])\n",
        "    date_range = (vars()[data_df]['DateTime'].min(), vars()[data_df]['DateTime'].max())\n",
        "    print(f\"Date range: {date_range[0]} to {date_range[1]}\")\n",
        "    display(vars()[data_df].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "252ffd50",
      "metadata": {
        "id": "252ffd50"
      },
      "source": [
        "#### Looks interesting, let's plot!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8823371-f416-4fdc-a44c-a6fbb3dc2e25",
      "metadata": {
        "id": "c8823371-f416-4fdc-a44c-a6fbb3dc2e25"
      },
      "source": [
        "### 3. Plot the data to visualize basic patterns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c0ab98b-0d28-4d53-9c11-10cda219f546",
      "metadata": {
        "id": "0c0ab98b-0d28-4d53-9c11-10cda219f546"
      },
      "source": [
        "<strong><span style=\"color:blue\">Enter INPUT</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67f054ba-1469-4f16-8458-5e4f7eaf799c",
      "metadata": {
        "id": "67f054ba-1469-4f16-8458-5e4f7eaf799c"
      },
      "outputs": [],
      "source": [
        "## DEEP DIVE API RESULT\n",
        "\n",
        "# Select the dataset you want to plot\n",
        "dataframe = data_df_deep_dive\n",
        "\n",
        "# Select the variables that you are interest in plotting\n",
        "variables_of_interest = ['Temperature','Specific_Conductance']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b31fc798-c8c8-4559-87c2-42ae306afea0",
      "metadata": {
        "id": "b31fc798-c8c8-4559-87c2-42ae306afea0"
      },
      "source": [
        "<strong><span style=\"color:green\">Run Cell</span></strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f749f66d-5174-4581-bd99-173c60447443",
      "metadata": {
        "id": "f749f66d-5174-4581-bd99-173c60447443"
      },
      "outputs": [],
      "source": [
        "# Plot the data\n",
        "# ===================================\n",
        "# Convert 'DateTime'to datetime using:\n",
        "dataframe['DateTime'] = pd.to_datetime(dataframe['DateTime'])\n",
        "\n",
        "num_plots = len(variables_of_interest)\n",
        "\n",
        "# Create a figure with two subplots\n",
        "fig, axs = plt.subplots(num_plots, 1, figsize=(10, 8))\n",
        "\n",
        "for i, ax in enumerate(axs):\n",
        "    # Plot VARIABLE over time\n",
        "    ax.plot(dataframe['DateTime'], dataframe[variables_of_interest[i]], label=variables_of_interest[i])\n",
        "    ax.set_title(variables_of_interest[i] + ' over Time')\n",
        "    ax.set_xlabel('DateTime')\n",
        "    ax.set_ylabel(variables_of_interest[i])\n",
        "    ax.grid(True)\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27dc3f34",
      "metadata": {
        "id": "27dc3f34"
      },
      "source": [
        "### Using this plot, we can visually see the data coverage, and start to think about patterns in the data.\n",
        "### Visualizing the data can help you determine if this data file may work for your science question. You can keep going with analysis by inserting your custom analysis code here! Or, you can move on to the next section and download the data for future use.\n",
        "RESOURCE: [Python pandas user guide](https://pandas.pydata.org/docs/user_guide/index.html#user-guide)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a480ed1d-e19c-4a00-8d3d-bcc31590de26",
      "metadata": {
        "id": "a480ed1d-e19c-4a00-8d3d-bcc31590de26"
      },
      "source": [
        "### Move on to Part 4 if you wish to download the data.\n",
        "You will need to change the variable names to download the correct files from this workflow"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e91d33c",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "8e91d33c"
      },
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4e1ac57-4fed-4c71-8ca2-06ae7b754af2",
      "metadata": {
        "id": "c4e1ac57-4fed-4c71-8ca2-06ae7b754af2"
      },
      "source": [
        "# EXTRA. Finding data using Sample ID and Metadata Reporting Formats - workflow\n",
        "\n",
        "### Tutorial_FindingAccessData.ipynb - 2023 ESS-DIVE Community Workshop\n",
        "This notebook [Tutorial_FindingAccessData.ipynb](https://github.com/ess-dive/essdive-tutorials/blob/main/search_data/Tutorial_FindingAccessingData.ipynb) is from the Finding and Accessing Data Tutorial 2023. It contains a similar workflow to this notebook (albeit without the Deep Dive API), but also additional information and code including:\n",
        "\n",
        "1. (Step 6 of DSC's notebook) Using Sample ID and Metadata Reporting Formats\n",
        "   - The example utilizes data that contain the Sample ID reporting formats.\n",
        "   - It utilizes the same basic tools: Dataset API, inspecting reporting format files, etc to provide another way to utilize ESS-DIVE data\n",
        "   - You will want to run Steps 1: Set Up before running Step 6: Sample ID and Metadata Reporting Formats."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c8447d3-0256-4ac3-b158-5dce94dc6e3c",
      "metadata": {
        "id": "0c8447d3-0256-4ac3-b158-5dce94dc6e3c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "stml",
      "language": "python",
      "name": "stml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}